{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ffbf67ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from rl.agents import DQNAgent\n",
    "import gym\n",
    "from gym import spaces\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from rl.agents import DQNAgent\n",
    "from rl.policy import EpsGreedyQPolicy\n",
    "from rl.memory import SequentialMemory\n",
    "from rl.core import Processor\n",
    "from keras.callbacks import TensorBoard\n",
    "# from rl.callbacks import Callback\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5e4a74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "years_files = {\n",
    "    # 2021: \"../Data/merged_2021.xlsx\",\n",
    "    2022: \"../Data/merged_2022.xlsx\",\n",
    "    2023: \"../Data/merged_2023.xlsx\"\n",
    "}\n",
    "dfs = []\n",
    "\n",
    "for year, file_path in years_files.items():\n",
    "    df = pd.read_excel(file_path, engine='openpyxl')\n",
    "    df['Year'] = year\n",
    "    dfs.append(df)\n",
    "    \n",
    "data = pd.concat(dfs, ignore_index=True)\n",
    "pop_data = pd.read_excel('../Data/state_level_population_projection_wide_xgboost.xlsx')\n",
    "pop_data_melted = pop_data.melt(\n",
    "    id_vars=['Variant', 'Variant Description', 'Year', 'Age'],\n",
    "    value_vars=['Baden-Württemberg', 'Bayern', 'Berlin', 'Brandenburg', 'Bremen',\n",
    "               'Hamburg', 'Hessen', 'Mecklenburg-Vorpommern', 'Niedersachsen',\n",
    "               'Nordrhein-Westfalen', 'Rheinland-Pfalz', 'Saarland', 'Sachsen',\n",
    "               'Sachsen-Anhalt', 'Schleswig-Holstein', 'Thüringen'],\n",
    "    var_name='state',\n",
    "    value_name='population'\n",
    ")\n",
    "merged_data_population = pd.merge(\n",
    "    data,\n",
    "    pop_data_melted,\n",
    "    left_on=['state', 'Year'],\n",
    "    right_on=['state', 'Year'],\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4698abdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ali\\AppData\\Local\\Temp\\ipykernel_36804\\2987491451.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_data_population[col + '_encoded'] = le.fit_transform(merged_data_population[col].astype(str))\n",
      "C:\\Users\\Ali\\AppData\\Local\\Temp\\ipykernel_36804\\2987491451.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_data_population[col + '_encoded'] = le.fit_transform(merged_data_population[col].astype(str))\n",
      "C:\\Users\\Ali\\AppData\\Local\\Temp\\ipykernel_36804\\2987491451.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_data_population[col + '_encoded'] = le.fit_transform(merged_data_population[col].astype(str))\n"
     ]
    }
   ],
   "source": [
    "label_encoders = {}\n",
    "categorical_cols = ['state', 'MDC', 'Age']\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    merged_data_population[col + '_encoded'] = le.fit_transform(merged_data_population[col].astype(str))\n",
    "    label_encoders[col] = le  # Save encoders for later use\n",
    "# Normalize numerical columns (e.g., 'total_patients')\n",
    "scaler = StandardScaler()\n",
    "numerical_cols = merged_data_population.columns.difference(['state', 'MDC','Variant','Variant Description','Fachabteilung', 'Sekundär','state_encoded','MDC_encoded','Land_x','Land_y'])\n",
    "numerical_cols = [str(col) for col in numerical_cols]\n",
    "merged_data_population[numerical_cols] = scaler.fit_transform(merged_data_population[numerical_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8b12787",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data_population[merged_data_population.select_dtypes(include='number').columns] = merged_data_population.select_dtypes(include='number').fillna(0)\n",
    "merged_data_population[merged_data_population.select_dtypes(include='object').columns] = merged_data_population.select_dtypes(include='object').fillna(\"unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd7364e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_columns = []\n",
    "state_columns.extend(numerical_cols)\n",
    "state_columns.extend(['state_encoded','total_patients'])\n",
    "len(state_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dfbcea63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mdc_mapping import mdc_to_fachabteilung\n",
    "class ReshapeProcessor(Processor):\n",
    "    def process_state_batch(self, state_batch):\n",
    "        # Remove the extra dimension: (batch, 1, 2) → (batch, 2)\n",
    "        return np.squeeze(state_batch, axis=1)\n",
    "    \n",
    "class HospitalEnv(gym.Env):\n",
    "    def __init__(self, data):\n",
    "        super(HospitalEnv, self).__init__()\n",
    "        self.data = data\n",
    "        self.num_beds = 6\n",
    "        self.mdc_to_fachabteilung = mdc_to_fachabteilung\n",
    "        self.state_size = 200  # patients, state\n",
    "        self.observation_space = spaces.Box(low=0, high=1, shape=(self.state_size,), dtype=np.float32)\n",
    "        self.mdc_list = list(mdc_to_fachabteilung.keys())\n",
    "        self.action_space = spaces.Discrete(len(self.mdc_list) * self.num_beds)  # n_depts * beds allowed to re allocate\n",
    "        self.mdc_to_index = {mdc: idx for idx, mdc in enumerate(self.mdc_list)}\n",
    "        self.index_to_mdc = {idx: mdc for mdc, idx in self.mdc_to_index.items()}\n",
    "        self.dept_columns = [col for col in data.columns if col.startswith(('0'))]\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=0, high=1, shape=(len(state_columns),), dtype=np.float32\n",
    "        )\n",
    "        self.label_encoders = label_encoders\n",
    "        \n",
    "        \n",
    "    def decode_action(self, action):\n",
    "        mdc = action // self.num_beds\n",
    "        beds = action % self.num_beds\n",
    "        return mdc, beds\n",
    "    \n",
    "    def _add_beds(self):\n",
    "        \"\"\"Adds 10 beds to the most overcrowded department.\"\"\"\n",
    "        utilization = self.current_patient[self.dept_columns] / self.current_patient[self.dept_columns].max()\n",
    "        worst_dept = self.dept_columns[np.argmax(utilization)]\n",
    "        self.current_patient[worst_dept] += 10\n",
    "        self.current_patient['INSG_x'] += 10\n",
    "        \n",
    "    def _get_state(self):\n",
    "        # Extract ONLY the two features we need\n",
    "        # print(self.current_patient[numerical_cols])\n",
    "        out = self.current_patient[state_columns].values.flatten()\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def _calculate_reward(self, old_state,action):\n",
    "\n",
    "        mdc_index, _ = self.decode_action(action)\n",
    "        mdc_label = self.label_encoders[\"MDC\"].inverse_transform([mdc_index])[0]\n",
    "        mapped_depts = mdc_to_fachabteilung.get(mdc_label, {})\n",
    "        relevant_depts = mapped_depts.get(\"Fachabteilung\", []) + mapped_depts.get(\"Sekundär\", [])\n",
    "        \n",
    "        current_patients = self.current_patient['total_patients'].values[0]\n",
    "        bed_values = self.current_patient[self.dept_columns].values.flatten()\n",
    "        \n",
    "        bed_ratios = bed_values / (current_patients + 1e-6)\n",
    "        # Penalty for overcrowding (patients > beds)\n",
    "        overcrowding_penalty = np.sum(np.where(bed_ratios < 1, 1 - bed_ratios, 0))\n",
    "\n",
    "        balance_score = (np.mean(bed_ratios)) / (np.std(bed_ratios) + 1e-6)\n",
    "        balance_reward = np.clip(balance_score, 0, 10) # Avoid division by zero\n",
    "        # print(balance_reward)\n",
    "        \n",
    "        target_depts = set(relevant_depts)\n",
    "        present_depts = set(self.dept_columns)\n",
    "        matching_depts = target_depts & present_depts\n",
    "        is_diagnostic_correct = False\n",
    "        if matching_depts:\n",
    "            is_diagnostic_correct = True\n",
    "            \n",
    "        # correct_mdc = self.current_patient['MDC_encoded'].values[0]\n",
    "        diagnostic_reward = 1 if is_diagnostic_correct else -5\n",
    "        total_reward = (\n",
    "        0.7 * balance_reward +    \n",
    "        0.3 * diagnostic_reward -           \n",
    "        overcrowding_penalty      # Penalty (unweighted, absolute)\n",
    "        ) \n",
    "        return float(total_reward)\n",
    "    \n",
    "    def reset(self):\n",
    "        # Randomly select a patient case\n",
    "        self.current_patient = self.data.sample(1)\n",
    "        return self._get_state()\n",
    "    \n",
    "    def _reallocate_beds(self, mdc_index, beds):\n",
    "        mdc_label = self.label_encoders[\"MDC\"].inverse_transform([mdc_index])[0]\n",
    "        mapping = mdc_to_fachabteilung.get(mdc_label, {})\n",
    "        fach = mapping.get(\"Fachabteilung\", [])\n",
    "        sek = mapping.get(\"Sekundär\", [])\n",
    "        target_depts = list(set(fach + sek))\n",
    "        present_depts = [d for d in target_depts if d in self.dept_columns]\n",
    "\n",
    "        if len(present_depts) < 2 or beds == 0:\n",
    "            return  \n",
    "\n",
    "        util = self.current_patient[present_depts].values.flatten()\n",
    "        from_dept = present_depts[np.argmax(util)]\n",
    "        to_dept = present_depts[np.argmin(util)]\n",
    "\n",
    "        self.current_patient[from_dept] = max(0, self.current_patient[from_dept] - beds)\n",
    "        self.current_patient[to_dept] += beds\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    def step(self, action):\n",
    "        old_state = self._get_state()\n",
    "        mdc_index, beds_to_move = self.decode_action(action)\n",
    "        self._reallocate_beds(mdc_index, beds_to_move)\n",
    "        reward = self._calculate_reward(old_state, action)\n",
    "        done = True  \n",
    "        return self.reset(), reward, done, {}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "724e98c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"logs/fit/\" + time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(\n",
    "    log_dir=log_dir,\n",
    "    histogram_freq=0,\n",
    "    write_graph=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede8d0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from logger import log_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e14e208e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rl.callbacks import Callback\n",
    "import tensorflow as tf\n",
    "class CustomTensorBoardCallback(Callback):\n",
    "    def __init__(self, log_dir=\"./logs/\"):\n",
    "        self.writer = tf.summary.create_file_writer(log_dir)\n",
    "        self.step = 0\n",
    "\n",
    "    def on_step_end(self, step, logs={}):\n",
    "        self.step += 1\n",
    "        with self.writer.as_default():\n",
    "            if 'reward' in logs:\n",
    "                tf.summary.scalar('reward', logs['reward'], step=self.step)\n",
    "            if 'loss' in logs:\n",
    "                tf.summary.scalar('loss', logs['loss'], step=self.step)\n",
    "            self.writer.flush()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a1281e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 10000 steps ...\n",
      "Interval 1 (0 steps performed)\n",
      " 1443/10000 [===>..........................] - ETA: 1:04:16 - reward: -81.3280"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "mdc_list = list(mdc_to_fachabteilung.keys())\n",
    "policy = EpsGreedyQPolicy()\n",
    "memory = SequentialMemory(limit=50000, window_length=1)\n",
    "model = Sequential([\n",
    "    Dense(1024, activation='relu', input_shape=(200,)),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(len(mdc_list) * 6, activation='linear')  #Number of distinct departments * number_beds\n",
    "])\n",
    "        \n",
    "# Add the processor to your agent\n",
    "agent = DQNAgent(\n",
    "    model=model,\n",
    "    policy=policy,\n",
    "    memory=memory,\n",
    "    nb_steps_warmup=1000,\n",
    "    nb_actions=len(mdc_list) * 6,\n",
    "    batch_size=64,\n",
    "    enable_double_dqn=True,\n",
    "    processor=ReshapeProcessor()  # Fixes shape issues\n",
    ")\n",
    "\n",
    "agent.compile(optimizer='adam')\n",
    "\n",
    "# Train the agent\n",
    "env = HospitalEnv(merged_data_population)\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    agent.fit(env, nb_steps=10000, visualize=False, callbacks=[CustomTensorBoardCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60781c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = HospitalEnv(data)\n",
    "state = env.reset()\n",
    "print(\"State shape:\", state.shape)  # Should be (2,)\n",
    "print(\"State values:\", state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5772cff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = agent.test(env, nb_episodes=100, visualize=False)\n",
    "print(\"Average reward:\", np.mean(scores.history['episode_reward']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "760a6a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Department: ['-1 – Fehler-DRGs und sonstige DRGs']\n"
     ]
    }
   ],
   "source": [
    "test_obs = env.reset()\n",
    "action = agent.forward(test_obs)\n",
    "print(f\"Recommended Department: {label_encoders['MDC'].inverse_transform([action])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8fdbf617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "21a1904a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir=./logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4962e75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
