{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffbf67ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from rl.agents import DQNAgent\n",
    "import gym\n",
    "from gym import spaces\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from rl.agents import DQNAgent\n",
    "from rl.policy import EpsGreedyQPolicy\n",
    "from rl.memory import SequentialMemory\n",
    "from rl.core import Processor\n",
    "from keras.callbacks import TensorBoard\n",
    "# from rl.callbacks import Callback\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5e4a74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "years_files = {\n",
    "    # 2021: \"../Data/merged_2021.xlsx\",\n",
    "    2022: \"../Data/merged_2022.xlsx\",\n",
    "    2023: \"../Data/merged_2023.xlsx\"\n",
    "}\n",
    "dfs = []\n",
    "\n",
    "for year, file_path in years_files.items():\n",
    "    df = pd.read_excel(file_path, engine='openpyxl')\n",
    "    df['Year'] = year\n",
    "    dfs.append(df)\n",
    "    \n",
    "data = pd.concat(dfs, ignore_index=True)\n",
    "pop_data = pd.read_excel('../Data/state_level_population_projection_wide_xgboost.xlsx')\n",
    "pop_data_melted = pop_data.melt(\n",
    "    id_vars=['Variant', 'Variant Description', 'Year', 'Age'],\n",
    "    value_vars=['Baden-Württemberg', 'Bayern', 'Berlin', 'Brandenburg', 'Bremen',\n",
    "               'Hamburg', 'Hessen', 'Mecklenburg-Vorpommern', 'Niedersachsen',\n",
    "               'Nordrhein-Westfalen', 'Rheinland-Pfalz', 'Saarland', 'Sachsen',\n",
    "               'Sachsen-Anhalt', 'Schleswig-Holstein', 'Thüringen'],\n",
    "    var_name='state',\n",
    "    value_name='population'\n",
    ")\n",
    "merged_data_population = pd.merge(\n",
    "    data,\n",
    "    pop_data_melted,\n",
    "    left_on=['state', 'Year'],\n",
    "    right_on=['state', 'Year'],\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4698abdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ali\\AppData\\Local\\Temp\\ipykernel_16552\\2987491451.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_data_population[col + '_encoded'] = le.fit_transform(merged_data_population[col].astype(str))\n",
      "C:\\Users\\Ali\\AppData\\Local\\Temp\\ipykernel_16552\\2987491451.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_data_population[col + '_encoded'] = le.fit_transform(merged_data_population[col].astype(str))\n",
      "C:\\Users\\Ali\\AppData\\Local\\Temp\\ipykernel_16552\\2987491451.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_data_population[col + '_encoded'] = le.fit_transform(merged_data_population[col].astype(str))\n"
     ]
    }
   ],
   "source": [
    "label_encoders = {}\n",
    "categorical_cols = ['state', 'MDC', 'Age']\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    merged_data_population[col + '_encoded'] = le.fit_transform(merged_data_population[col].astype(str))\n",
    "    label_encoders[col] = le  # Save encoders for later use\n",
    "# Normalize numerical columns (e.g., 'total_patients')\n",
    "scaler = StandardScaler()\n",
    "numerical_cols = merged_data_population.columns.difference(['state', 'MDC','Variant','Variant Description','Fachabteilung', 'Sekundär','state_encoded','MDC_encoded','Land_x','Land_y'])\n",
    "numerical_cols = [str(col) for col in numerical_cols]\n",
    "merged_data_population[numerical_cols] = scaler.fit_transform(merged_data_population[numerical_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8b12787",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data_population[merged_data_population.select_dtypes(include='number').columns] = merged_data_population.select_dtypes(include='number').fillna(0)\n",
    "merged_data_population[merged_data_population.select_dtypes(include='object').columns] = merged_data_population.select_dtypes(include='object').fillna(\"unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd7364e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_columns = []\n",
    "state_columns.extend(numerical_cols)\n",
    "state_columns.extend(['state_encoded','total_patients'])\n",
    "len(state_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa131f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "class iFCAAccessibility:\n",
    "    \"\"\"\n",
    "    Integrated Floating Catchment Area (iFCA) implementation for hospital accessibility\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, distance_threshold=50, distance_decay_function='gaussian', beta=1.0):\n",
    "        \"\"\"\n",
    "        Initialize iFCA calculator\n",
    "        \n",
    "        Args:\n",
    "            distance_threshold: Maximum distance to consider (km)\n",
    "            distance_decay_function: 'linear', 'exponential', 'gaussian', or 'power'\n",
    "            beta: Decay parameter for distance functions\n",
    "        \"\"\"\n",
    "        self.distance_threshold = distance_threshold\n",
    "        self.distance_decay_function = distance_decay_function\n",
    "        self.beta = beta\n",
    "        \n",
    "    def _calculate_distance_decay(self, distances):\n",
    "        \"\"\"Calculate distance decay weights\"\"\"\n",
    "        # Mask distances beyond threshold\n",
    "        distances = np.where(distances <= self.distance_threshold, distances, np.inf)\n",
    "        \n",
    "        if self.distance_decay_function == 'linear':\n",
    "            weights = np.where(distances != np.inf, \n",
    "                             1 - (distances / self.distance_threshold), 0)\n",
    "        elif self.distance_decay_function == 'exponential':\n",
    "            weights = np.where(distances != np.inf, \n",
    "                             np.exp(-self.beta * distances), 0)\n",
    "        elif self.distance_decay_function == 'gaussian':\n",
    "            weights = np.where(distances != np.inf, \n",
    "                             np.exp(-0.5 * (distances / self.beta) ** 2), 0)\n",
    "        elif self.distance_decay_function == 'power':\n",
    "            weights = np.where(distances != np.inf, \n",
    "                             distances ** (-self.beta), 0)\n",
    "        else:\n",
    "            # Default to inverse distance\n",
    "            weights = np.where(distances != np.inf, 1 / (distances + 1), 0)\n",
    "            \n",
    "        return weights\n",
    "    \n",
    "    def compute_ifca_accessibility(self, hospitals_df, population_df, \n",
    "                                  hospital_coords_cols=['lat', 'lon'],\n",
    "                                  population_coords_cols=['lat', 'lon'],\n",
    "                                  hospital_capacity_col='total_beds',\n",
    "                                  population_demand_col='population',\n",
    "                                  service_type_col=None):\n",
    "        \"\"\"\n",
    "        Compute iFCA accessibility scores\n",
    "        \n",
    "        Args:\n",
    "            hospitals_df: DataFrame with hospital data\n",
    "            population_df: DataFrame with population/demand data\n",
    "            hospital_coords_cols: Column names for hospital coordinates\n",
    "            population_coords_cols: Column names for population coordinates\n",
    "            hospital_capacity_col: Column name for hospital capacity (beds)\n",
    "            population_demand_col: Column name for population/demand\n",
    "            service_type_col: Column name for service type matching (optional)\n",
    "        \n",
    "        Returns:\n",
    "            accessibility_scores: Array of accessibility scores for each population location\n",
    "        \"\"\"\n",
    "        hospital_coords = hospitals_df[hospital_coords_cols].values\n",
    "        population_coords = population_df[population_coords_cols].values\n",
    "\n",
    "        distance_matrix = cdist(population_coords, hospital_coords, metric='euclidean')\n",
    "        \n",
    "        distance_matrix = distance_matrix * 111  \n",
    "        hospital_capacity = hospitals_df[hospital_capacity_col].values\n",
    "        population_demand = population_df[population_demand_col].values\n",
    "        \n",
    "        hospital_ratios = np.zeros(len(hospitals_df))\n",
    "        \n",
    "        for j, hospital_cap in enumerate(hospital_capacity):\n",
    "            distances_to_hospital = distance_matrix[:, j]\n",
    "            weights = self._calculate_distance_decay(distances_to_hospital)\n",
    "        \n",
    "            weighted_demand = np.sum(population_demand * weights)\n",
    "\n",
    "            if weighted_demand > 0:\n",
    "                hospital_ratios[j] = hospital_cap / weighted_demand\n",
    "            else:\n",
    "                hospital_ratios[j] = 0\n",
    "\n",
    "        accessibility_scores = np.zeros(len(population_df))\n",
    "        \n",
    "        for i in range(len(population_df)):\n",
    "            distances_to_hospitals = distance_matrix[i, :]\n",
    "            weights = self._calculate_distance_decay(distances_to_hospitals)\n",
    "            accessibility_scores[i] = np.sum(hospital_ratios * weights)\n",
    "        \n",
    "        return accessibility_scores\n",
    "\n",
    "def compute_iFCA_accessibility(hospitals_data, population_data=None, \n",
    "                              mdc_type=None, current_patient_state=None,\n",
    "                              mdc_to_fachabteilung=None):\n",
    "\n",
    "    ifca_calc = iFCAAccessibility(distance_threshold=100, \n",
    "                                 distance_decay_function='gaussian', \n",
    "                                 beta=20)\n",
    "\n",
    "    hospitals_df = hospitals_data.copy()\n",
    "    \n",
    "    dept_columns = [col for col in hospitals_df.columns if col.startswith(('0', '1', '2', '3', '8', '9'))]\n",
    "    \n",
    "    # Calculate service-specific beds if MDC is provided\n",
    "    if mdc_type and mdc_to_fachabteilung and mdc_type in mdc_to_fachabteilung:\n",
    "        # Get relevant departments for this MDC\n",
    "        mapping = mdc_to_fachabteilung[mdc_type]\n",
    "        primary_depts = mapping.get(\"Fachabteilung\", [])\n",
    "        secondary_depts = mapping.get(\"Sekundär\", [])\n",
    "        \n",
    "        # Find available departments in the data\n",
    "        relevant_depts = []\n",
    "        for dept in primary_depts + secondary_depts:\n",
    "            # Check if department exists in data (with or without leading zeros)\n",
    "            dept_variations = [dept, dept.lstrip('0'), f\"{int(dept):04d}\"]\n",
    "            for variation in dept_variations:\n",
    "                if variation in dept_columns:\n",
    "                    relevant_depts.append(variation)\n",
    "                    break\n",
    "        \n",
    "        if relevant_depts:\n",
    "            # Calculate beds for relevant departments only\n",
    "            hospitals_df['service_beds'] = hospitals_df[relevant_depts].sum(axis=1, skipna=True)\n",
    "            capacity_col = 'service_beds'\n",
    "        else:\n",
    "            # Fallback to total beds if no specific departments found\n",
    "            hospitals_df['total_beds'] = hospitals_df[dept_columns].sum(axis=1, skipna=True)\n",
    "            capacity_col = 'total_beds'\n",
    "    else:\n",
    "        # Calculate total available beds across all departments\n",
    "        hospitals_df['total_beds'] = hospitals_df[dept_columns].sum(axis=1, skipna=True)\n",
    "        capacity_col = 'total_beds'\n",
    "    \n",
    "    # Add dummy coordinates if not present (replace with actual coordinates)\n",
    "    if 'lat' not in hospitals_df.columns:\n",
    "        np.random.seed(42)  # For reproducibility\n",
    "        hospitals_df['lat'] = np.random.uniform(47, 55, len(hospitals_df))  # Germany latitude range\n",
    "        hospitals_df['lon'] = np.random.uniform(6, 15, len(hospitals_df))   # Germany longitude range\n",
    "    \n",
    "    # Prepare population data\n",
    "    if population_data is None:\n",
    "        # Use the same data as population centers\n",
    "        population_df = hospitals_data.copy()\n",
    "        population_df['population'] = population_df.get('population', 1000)  # Default population\n",
    "    else:\n",
    "        population_df = population_data.copy()\n",
    "    \n",
    "    # Add dummy coordinates for population if not present\n",
    "    if 'lat' not in population_df.columns:\n",
    "        np.random.seed(123)\n",
    "        population_df['lat'] = np.random.uniform(47, 55, len(population_df))\n",
    "        population_df['lon'] = np.random.uniform(6, 15, len(population_df))\n",
    "    \n",
    "    # Filter hospitals with capacity > 0\n",
    "    capacity_mask = hospitals_df[capacity_col] > 0\n",
    "    hospitals_df = hospitals_df[capacity_mask]\n",
    "    \n",
    "    # Ensure we have valid data\n",
    "    if len(hospitals_df) == 0 or hospitals_df[capacity_col].sum() == 0:\n",
    "        return np.array([0.0] * len(population_df))\n",
    "    \n",
    "    # Compute accessibility\n",
    "    try:\n",
    "        accessibility_scores = ifca_calc.compute_ifca_accessibility(\n",
    "            hospitals_df=hospitals_df,\n",
    "            population_df=population_df,\n",
    "            hospital_capacity_col=capacity_col,\n",
    "            population_demand_col='population'\n",
    "        )\n",
    "        \n",
    "        return accessibility_scores\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error computing iFCA accessibility: {e}\")\n",
    "        return np.array([0.0] * len(population_df))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "02df2e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified HospitalEnv class methods to integrate iFCA\n",
    "class HospitalEnvWithiFCA:\n",
    "    \"\"\"\n",
    "    Modified HospitalEnv class with proper iFCA integration\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data, mdc_to_fachabteilung):\n",
    "        # ... (keep your existing initialization code)\n",
    "        self.data = data\n",
    "        self.num_beds = 6\n",
    "        self.state_size = 200\n",
    "        self.mdc_to_fachabteilung = mdc_to_fachabteilung\n",
    "        \n",
    "        # Get all department columns (updated to include all department codes)\n",
    "        self.dept_columns = [col for col in data.columns if col.startswith(('0', '1', '2', '3', '8', '9'))]\n",
    "        \n",
    "        # Initialize iFCA calculator\n",
    "        self.ifca_calculator = iFCAAccessibility(\n",
    "            distance_threshold=100,\n",
    "            distance_decay_function='gaussian',\n",
    "            beta=20\n",
    "        )\n",
    "        \n",
    "        # Calculate initial accessibility baseline\n",
    "        self.previous_accessibility = self._compute_current_accessibility()\n",
    "    \n",
    "    def _compute_current_accessibility(self, mdc_type=None):\n",
    "        \"\"\"Compute accessibility for current hospital configuration\"\"\"\n",
    "        try:\n",
    "            # Use the updated compute_iFCA_accessibility function\n",
    "            accessibility_scores = compute_iFCA_accessibility(\n",
    "                hospitals_data=self.data,\n",
    "                mdc_type=mdc_type,\n",
    "                mdc_to_fachabteilung=self.mdc_to_fachabteilung\n",
    "            )\n",
    "            \n",
    "            return accessibility_scores\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error computing accessibility: {e}\")\n",
    "            return np.array([0.0])\n",
    "    \n",
    "    def _reallocate_beds_with_mapping(self, mdc_index, beds):\n",
    "        \"\"\"\n",
    "        Reallocate beds using the MDC to department mapping\n",
    "        \"\"\"\n",
    "        # Get MDC from index\n",
    "        mdc_list = list(self.mdc_to_fachabteilung.keys())\n",
    "        if mdc_index >= len(mdc_list):\n",
    "            return\n",
    "        \n",
    "        mdc_label = mdc_list[mdc_index]\n",
    "        \n",
    "        # Get department mapping\n",
    "        mapping = self.mdc_to_fachabteilung.get(mdc_label, {})\n",
    "        primary_depts = mapping.get(\"Fachabteilung\", [])\n",
    "        secondary_depts = mapping.get(\"Sekundär\", [])\n",
    "        \n",
    "        # Find available departments in current data\n",
    "        available_depts = []\n",
    "        for dept in primary_depts + secondary_depts:\n",
    "            # Check different variations of department codes\n",
    "            dept_variations = [dept, dept.lstrip('0'), f\"{int(dept):04d}\"]\n",
    "            for variation in dept_variations:\n",
    "                if variation in self.dept_columns:\n",
    "                    available_depts.append(variation)\n",
    "                    break\n",
    "        \n",
    "        if len(available_depts) < 2 or beds == 0:\n",
    "            return\n",
    "        \n",
    "        # Get current utilization for available departments\n",
    "        current_utilization = {}\n",
    "        for dept in available_depts:\n",
    "            current_utilization[dept] = self.current_patient[dept].iloc[0] if dept in self.current_patient.columns else 0\n",
    "        \n",
    "        # Find source (highest utilization) and target (lowest utilization) departments\n",
    "        if current_utilization:\n",
    "            source_dept = max(current_utilization, key=current_utilization.get)\n",
    "            target_dept = min(current_utilization, key=current_utilization.get)\n",
    "            \n",
    "            # Reallocate beds\n",
    "            if source_dept in self.current_patient.columns and target_dept in self.current_patient.columns:\n",
    "                current_source = self.current_patient[source_dept].iloc[0]\n",
    "                self.current_patient.loc[self.current_patient.index[0], source_dept] = max(0, current_source - beds)\n",
    "                self.current_patient.loc[self.current_patient.index[0], target_dept] += beds\n",
    "    \n",
    "    \n",
    "    def _get_state(self):\n",
    "        # Extract ONLY the two features we need\n",
    "        # print(self.current_patient[numerical_cols])\n",
    "        out = self.current_patient[state_columns].values.flatten()\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def reset(self):\n",
    "        # Randomly select a patient case\n",
    "        self.current_patient = self.data.sample(1)\n",
    "        return self._get_state()\n",
    "    \n",
    "    def _calculate_reward(self, new_accessibility=None):\n",
    "        \"\"\"Calculate reward based on accessibility improvement\"\"\"\n",
    "        if new_accessibility is None:\n",
    "            new_accessibility = self._compute_current_accessibility()\n",
    "        \n",
    "        # Calculate improvement in mean accessibility\n",
    "        current_mean = np.mean(new_accessibility)\n",
    "        previous_mean = np.mean(self.previous_accessibility)\n",
    "        \n",
    "        reward = current_mean - previous_mean\n",
    "        \n",
    "        # Update previous accessibility\n",
    "        self.previous_accessibility = new_accessibility.copy()\n",
    "        \n",
    "        return reward\n",
    "    \n",
    "    def decode_action(self, action):\n",
    "        mdc = action // self.num_beds\n",
    "        beds = action % self.num_beds\n",
    "        return mdc, beds\n",
    "    \n",
    "    def step(self, action):\n",
    "        \"\"\"Modified step function with iFCA integration\"\"\"\n",
    "        # Decode and apply action\n",
    "        mdc_index, beds = self.decode_action(action)\n",
    "        \n",
    "        # Use the improved bed reallocation with mapping\n",
    "        self._reallocate_beds_with_mapping(mdc_index, beds)\n",
    "        \n",
    "        # Get the MDC type for service-specific accessibility calculation\n",
    "        mdc_list = list(self.mdc_to_fachabteilung.keys())\n",
    "        current_mdc = mdc_list[mdc_index] if mdc_index < len(mdc_list) else None\n",
    "        \n",
    "        # Compute new accessibility (service-specific)\n",
    "        new_accessibility = self._compute_current_accessibility(mdc_type=current_mdc)\n",
    "        \n",
    "        # Calculate reward\n",
    "        reward = self._calculate_reward(new_accessibility)\n",
    "        \n",
    "        # Get next state\n",
    "        next_state = self._get_state()\n",
    "        \n",
    "        # Check if episode is done\n",
    "        done = False  # Define your termination condition\n",
    "        \n",
    "        info = {\n",
    "            \"accessibility\": new_accessibility,\n",
    "            \"mean_accessibility\": np.mean(new_accessibility),\n",
    "            \"accessibility_std\": np.std(new_accessibility),\n",
    "            \"mdc_type\": current_mdc,\n",
    "            \"beds_reallocated\": beds\n",
    "        }\n",
    "        \n",
    "        return next_state, reward, done, info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b03fb89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing iFCA with MDC Mapping:\n",
      "==================================================\n",
      "Overall Accessibility - Mean: 0.0073\n",
      "01 - Nervensystem - Mean: 0.0018\n",
      "05 – Kreislaufsystem - Mean: 0.0016\n",
      "08 – Muskel-Skelett-System & Bindegewebe - Mean: 0.0039\n"
     ]
    }
   ],
   "source": [
    "from mdc_mapping import mdc_to_fachabteilung\n",
    "class ReshapeProcessor(Processor):\n",
    "    def process_state_batch(self, state_batch):\n",
    "        # Remove the extra dimension: (batch, 1, 2) → (batch, 2)\n",
    "        return np.squeeze(state_batch, axis=1)\n",
    "\n",
    "def Main(merged_data_population, mdc_to_fachabteilung):\n",
    "    \n",
    "    env = HospitalEnvWithiFCA(merged_data_population, mdc_to_fachabteilung)\n",
    "    mdc_list = list(mdc_to_fachabteilung.keys())\n",
    "    n_actions = len(mdc_list) * 6  # 6 beds per action\n",
    "    \n",
    "    model = Sequential([\n",
    "        Dense(128, activation='relu', input_shape=(200,)),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(n_actions, activation='linear')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    \n",
    "    # Create agent with updated action space\n",
    "    policy = EpsGreedyQPolicy()\n",
    "    memory = SequentialMemory(limit=50000, window_length=1)\n",
    "    \n",
    "    agent = DQNAgent(\n",
    "        model=model,\n",
    "        policy=policy,\n",
    "        memory=memory,\n",
    "        nb_steps_warmup=100,\n",
    "        nb_actions=n_actions,\n",
    "        batch_size=32,\n",
    "        enable_double_dqn=True,\n",
    "        processor=ReshapeProcessor()\n",
    "    )\n",
    "    \n",
    "    agent.compile(optimizer='adam')\n",
    "    \n",
    "    return env, agent\n",
    "\n",
    "env,agent = Main(merged_data_population,mdc_to_fachabteilung)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e14e208e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rl.callbacks import Callback\n",
    "import tensorflow as tf\n",
    "class CustomTensorBoardCallback(Callback):\n",
    "    def __init__(self, log_dir=\"./logs/\"):\n",
    "        self.writer = tf.summary.create_file_writer(log_dir)\n",
    "        self.step = 0\n",
    "\n",
    "    def on_step_end(self, step, logs={}):\n",
    "        self.step += 1\n",
    "        with self.writer.as_default():\n",
    "            if 'reward' in logs:\n",
    "                tf.summary.scalar('reward', logs['reward'], step=self.step)\n",
    "            if 'loss' in logs:\n",
    "                tf.summary.scalar('loss', logs['loss'], step=self.step)\n",
    "            self.writer.flush()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a1281e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "mdc_list = list(mdc_to_fachabteilung.keys())\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    agent.fit(env, nb_steps=10000, visualize=False, callbacks=[CustomTensorBoardCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60781c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = HospitalEnv(data)\n",
    "state = env.reset()\n",
    "print(\"State shape:\", state.shape)  # Should be (2,)\n",
    "print(\"State values:\", state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5772cff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = agent.test(env, nb_episodes=100, visualize=False)\n",
    "print(\"Average reward:\", np.mean(scores.history['episode_reward']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "760a6a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Department: ['-1 – Fehler-DRGs und sonstige DRGs']\n"
     ]
    }
   ],
   "source": [
    "test_obs = env.reset()\n",
    "action = agent.forward(test_obs)\n",
    "print(f\"Recommended Department: {label_encoders['MDC'].inverse_transform([action])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8fdbf617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "21a1904a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir=./logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4962e75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
