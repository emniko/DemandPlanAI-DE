{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12121847,"sourceType":"datasetVersion","datasetId":7632781}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"! pip install pygam","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T16:51:33.382873Z","iopub.execute_input":"2025-06-10T16:51:33.383578Z","iopub.status.idle":"2025-06-10T16:51:43.460995Z","shell.execute_reply.started":"2025-06-10T16:51:33.383551Z","shell.execute_reply":"2025-06-10T16:51:43.460309Z"}},"outputs":[{"name":"stdout","text":"Collecting pygam\n  Downloading pygam-0.9.1-py3-none-any.whl.metadata (7.1 kB)\nRequirement already satisfied: numpy>=1.25 in /usr/local/lib/python3.11/dist-packages (from pygam) (1.26.4)\nRequirement already satisfied: progressbar2<5.0.0,>=4.2.0 in /usr/local/lib/python3.11/dist-packages (from pygam) (4.5.0)\nCollecting scipy<1.12,>=1.11.1 (from pygam)\n  Downloading scipy-1.11.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.25->pygam) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.25->pygam) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.25->pygam) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.25->pygam) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.25->pygam) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.25->pygam) (2.4.1)\nRequirement already satisfied: python-utils>=3.8.1 in /usr/local/lib/python3.11/dist-packages (from progressbar2<5.0.0,>=4.2.0->pygam) (3.9.1)\nRequirement already satisfied: typing_extensions>3.10.0.2 in /usr/local/lib/python3.11/dist-packages (from python-utils>=3.8.1->progressbar2<5.0.0,>=4.2.0->pygam) (4.13.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.25->pygam) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.25->pygam) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.25->pygam) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.25->pygam) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.25->pygam) (2024.2.0)\nDownloading pygam-0.9.1-py3-none-any.whl (522 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m522.0/522.0 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading scipy-1.11.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.4/36.4 MB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: scipy, pygam\n  Attempting uninstall: scipy\n    Found existing installation: scipy 1.15.2\n    Uninstalling scipy-1.15.2:\n      Successfully uninstalled scipy-1.15.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.11.4 which is incompatible.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\ndopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\nimbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\nplotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\nmlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed pygam-0.9.1 scipy-1.11.4\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom statsmodels.tsa.holtwinters import ExponentialSmoothing\nfrom pygam import LinearGAM, s\nimport xgboost as xgb\nfrom functools import reduce\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")\n\n# Load your historical data\ncore_data = pd.read_csv(\"/kaggle/input/data-science/Historical.csv\")\ncore_data = core_data[core_data[\"Age\"] != \"Total\"]\ncore_data[\"Age\"] = core_data[\"Age\"].astype(int)\n\nstate_columns = [col for col in core_data.columns if col not in [\"Year\", \"Age\"]]\nfuture_years = np.arange(2022, 2071)\n\nall_preds = []\n\ndef predict_best_model(X, y, future_X):\n    # Split into train/test\n    split = int(0.8 * len(X))\n    X_train, X_test = X[:split], X[split:]\n    y_train, y_test = y[:split], y[split:]\n\n    results = {}\n\n    # Linear Regression\n    lr = LinearRegression().fit(X_train, y_train)\n    results[\"LR\"] = (lr, mean_squared_error(y_test, lr.predict(X_test)))\n\n    # XGBoost\n    xgb_model = xgb.XGBRegressor(objective=\"reg:squarederror\", n_estimators=100, max_depth=3)\n    xgb_model.fit(X_train, y_train)\n    results[\"XGB\"] = (xgb_model, mean_squared_error(y_test, xgb_model.predict(X_test)))\n\n    # GAM\n    try:\n        gam = LinearGAM(s(0)).fit(X_train.ravel(), y_train)\n        results[\"GAM\"] = (gam, mean_squared_error(y_test, gam.predict(X_test.ravel())))\n    except:\n        pass\n\n    # ETS (needs univariate series)\n    try:\n        ets_model = ExponentialSmoothing(y_train, trend=\"add\", seasonal=None).fit()\n        y_ets_pred = ets_model.forecast(len(y_test))\n        results[\"ETS\"] = (ets_model, mean_squared_error(y_test, y_ets_pred))\n    except:\n        pass\n\n    # Choose best\n    best_name = min(results, key=lambda k: results[k][1])\n    best_model = results[best_name][0]\n\n    # Predict future\n    if best_name == \"GAM\":\n        preds = best_model.predict(future_X.ravel())\n    elif best_name == \"ETS\":\n        preds = best_model.forecast(len(future_X))\n    else:\n        preds = best_model.predict(future_X)\n\n    return np.clip(preds, 0, 1), best_name\n\nbest_models_list = []\n\nfor state in state_columns:\n    state_preds = {\"Age\": [], \"Year\": [], state: []}\n    for age in core_data[\"Age\"].unique():\n        subset = core_data[core_data[\"Age\"] == age][[\"Year\", state]].dropna()\n        if len(subset) < 4:\n            continue\n\n        X = subset[\"Year\"].values.reshape(-1, 1)\n        y = subset[state].values\n\n        y_pred, chosen_model = predict_best_model(X, y, future_years.reshape(-1, 1))\n        # print(f\"Best model for {state} age {age}: {chosen_model}\")\n        best_models_list.append({\"State\": state, \"Age\": age, \"BestModel\": chosen_model})\n\n\n        state_preds[\"Age\"].extend([age] * len(future_years))\n        state_preds[\"Year\"].extend(future_years)\n        state_preds[state].extend(y_pred)\n\n    all_preds.append(pd.DataFrame(state_preds))\n\n# # Merge all predicted state share dataframes\n# predicted_shares_df = reduce(lambda left, right: pd.merge(left, right, on=[\"Age\", \"Year\"], how=\"outer\"), all_preds)\n\n# # Optional: Normalize to sum to 1 across states\n# predicted_shares_df[state_columns] = predicted_shares_df[state_columns].div(\n#     predicted_shares_df[state_columns].sum(axis=1), axis=0\n# )\n\n# # Save to file (optional)\n# # predicted_shares_df.to_csv(\"predicted_shares_by_best_model.csv\", index=False)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-10T16:59:10.863810Z","iopub.execute_input":"2025-06-10T16:59:10.864080Z","iopub.status.idle":"2025-06-10T17:00:08.881001Z","shell.execute_reply.started":"2025-06-10T16:59:10.864060Z","shell.execute_reply":"2025-06-10T17:00:08.880371Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# === Count how many times each model was used ===\nbest_models_df = pd.DataFrame(best_models_list)\n\n# Count overall\nmodel_counts = best_models_df[\"BestModel\"].value_counts()\nprint(\"Overall model usage counts:\")\nprint(model_counts)\n\n# Optional: Count per state\nmodel_counts_by_state = best_models_df.groupby(\"State\")[\"BestModel\"].value_counts().unstack(fill_value=0)\nprint(\"\\nModel usage per state:\")\nprint(model_counts_by_state)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T17:00:08.882148Z","iopub.execute_input":"2025-06-10T17:00:08.882451Z","iopub.status.idle":"2025-06-10T17:00:08.914113Z","shell.execute_reply.started":"2025-06-10T17:00:08.882421Z","shell.execute_reply":"2025-06-10T17:00:08.913347Z"}},"outputs":[{"name":"stdout","text":"Overall model usage counts:\nBestModel\nXGB    515\nETS    510\nLR     337\nGAM     94\nName: count, dtype: int64\n\nModel usage per state:\nBestModel               ETS  GAM  LR  XGB\nState                                    \nBaden-Württemberg        32    0  23   36\nBayern                   21    3  30   37\nBerlin                   30    5  20   36\nBrandenburg              31    9  20   31\nBremen                   27    5  30   29\nHamburg                  40    2  28   21\nHessen                   30    2  25   34\nMecklenburg-Vorpommern   32   16  15   28\nNiedersachsen            34    0  20   37\nNordrhein-Westfalen      33    1  19   38\nRheinland-Pfalz          40    2  22   27\nSaarland                 27    9  21   34\nSachsen                  30   14  16   31\nSachsen-Anhalt           26   12  16   37\nSchleswig-Holstein       47    3  18   23\nThüringen                30   11  14   36\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom xgboost import XGBRegressor\nfrom functools import reduce\n\n# === Step 1: Load Historical Core Data and Projection Data ===\ncore_data = pd.read_csv(\"/kaggle/input/data-science/Historical.csv\")\nprojection_data = pd.read_excel(\"/kaggle/input/data-science/Forecast.xlsx\")\n\n# === Step 2: Preprocess Historical State Shares ===\ncore_data = core_data[core_data[\"Age\"] != \"Total\"]\ncore_data[\"Age\"] = core_data[\"Age\"].astype(int)\nstate_columns = [col for col in core_data.columns if col not in [\"Year\", \"Age\"]]\n\n# === Step 3: Predict Future State Shares (Wide Format) ===\nfuture_years = np.arange(2022, 2071)\nall_preds = []\n\nfor state in state_columns:\n    # Prepare training data\n    df = core_data[[\"Year\", \"Age\", state]].dropna()\n    if len(df) < 3:\n        continue\n\n    X_train = df[[\"Year\", \"Age\"]]\n    y_train = df[state]\n\n    model = XGBRegressor(n_estimators=100, max_depth=3, learning_rate=0.1)\n    model.fit(X_train, y_train)\n\n    # Prepare future prediction grid\n    future_grid = pd.DataFrame([(y, a) for y in future_years for a in core_data[\"Age\"].unique()],\n                               columns=[\"Year\", \"Age\"])\n    y_pred = model.predict(future_grid)\n    y_pred = np.clip(y_pred, 0, 1)\n\n    state_preds = pd.DataFrame({\n        \"Year\": future_grid[\"Year\"],\n        \"Age\": future_grid[\"Age\"],\n        state: y_pred\n    })\n\n    all_preds.append(state_preds)\n\n# Merge all state predictions\npredicted_shares_df = reduce(lambda left, right: pd.merge(left, right, on=[\"Age\", \"Year\"], how=\"outer\"), all_preds)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T17:53:51.246488Z","iopub.execute_input":"2025-06-10T17:53:51.247042Z","iopub.status.idle":"2025-06-10T17:53:54.196301Z","shell.execute_reply.started":"2025-06-10T17:53:51.247020Z","shell.execute_reply":"2025-06-10T17:53:54.195768Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# === Step 4: Preprocess Projection Data ===\nprojection_data[\"Variant\"] = projection_data[\"Variant\"].ffill()\nprojection_data[\"Variant Description\"] = projection_data[\"Variant Description\"].ffill()\nprojection_data = projection_data[projection_data[\"Age\"] != \"Total\"]\nprojection_data[\"Age\"] = projection_data[\"Age\"].astype(int)\n\nproj_long = projection_data.melt(\n    id_vars=[\"Variant\", \"Variant Description\", \"Age\"],\n    var_name=\"Year\",\n    value_name=\"National_Pop_Thousands\"\n)\nproj_long[\"Year\"] = proj_long[\"Year\"].astype(int)\nproj_long[\"National_Pop\"] = proj_long[\"National_Pop_Thousands\"] * 1000","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T17:53:57.699889Z","iopub.execute_input":"2025-06-10T17:53:57.700608Z","iopub.status.idle":"2025-06-10T17:53:57.765235Z","shell.execute_reply.started":"2025-06-10T17:53:57.700584Z","shell.execute_reply":"2025-06-10T17:53:57.764669Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# === Step 5: Merge National Projections with Predicted Shares ===\nmerged = proj_long.merge(predicted_shares_df, on=[\"Age\", \"Year\"], how=\"left\")\n\n# === Step 6: Multiply Shares with National Population for Each State ===\nfor state in state_columns:\n    if state in merged:\n        merged[state] = merged[state] * merged[\"National_Pop\"]\n\n# === Step 7: Final Output in Wide Format ===\noutput_columns = [\"Variant\", \"Variant Description\", \"Year\", \"Age\"] + state_columns\nfinal_df = merged[output_columns]\nfinal_df.sort_values(by=[\"Variant\", \"Variant Description\", \"Year\", \"Age\"], inplace=True)\n\nfinal_df[[\"Variant\", \"Variant Description\", \"Year\"]] = final_df[[\"Variant\", \"Variant Description\", \"Year\"]].mask(\n    final_df[[\"Variant\", \"Variant Description\", \"Year\"]].eq(\n        final_df[[\"Variant\", \"Variant Description\", \"Year\"]].shift()\n    )\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T17:53:58.485757Z","iopub.execute_input":"2025-06-10T17:53:58.486274Z","iopub.status.idle":"2025-06-10T17:53:58.682992Z","shell.execute_reply.started":"2025-06-10T17:53:58.486250Z","shell.execute_reply":"2025-06-10T17:53:58.682085Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_35/4208701532.py:12: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  final_df.sort_values(by=[\"Variant\", \"Variant Description\", \"Year\", \"Age\"], inplace=True)\n/tmp/ipykernel_35/4208701532.py:14: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  final_df[[\"Variant\", \"Variant Description\", \"Year\"]] = final_df[[\"Variant\", \"Variant Description\", \"Year\"]].mask(\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# === Step 8: Save to Excel ===\nfinal_df.to_excel(\"state_level_projection_wide_xgboost.xlsx\", index=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T17:54:01.646790Z","iopub.execute_input":"2025-06-10T17:54:01.647704Z","iopub.status.idle":"2025-06-10T17:54:36.701416Z","shell.execute_reply.started":"2025-06-10T17:54:01.647669Z","shell.execute_reply":"2025-06-10T17:54:36.700830Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}