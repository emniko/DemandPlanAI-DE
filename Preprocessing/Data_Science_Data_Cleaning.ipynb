{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRm0B0b5Mi_g",
        "outputId": "f1e2dbb7-61ec-4917-f5b1-70da5395ad57"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: jaydebeapi in /usr/local/lib/python3.11/dist-packages (1.2.3)\n",
            "Requirement already satisfied: JPype1 in /usr/local/lib/python3.11/dist-packages (from jaydebeapi) (1.5.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from JPype1->jaydebeapi) (24.2)\n"
          ]
        }
      ],
      "source": [
        "!apt-get install openjdk-8-jdk -qq > /dev/null\n",
        "!pip install jaydebeapi\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mnqCt6KMjjT",
        "outputId": "2bdc42d7-b11f-4a00-8165-6e74e6b15762"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting jaydebeapi\n",
            "  Downloading JayDeBeApi-1.2.3-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting JPype1 (from jaydebeapi)\n",
            "  Downloading jpype1-1.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from JPype1->jaydebeapi) (24.2)\n",
            "Downloading JayDeBeApi-1.2.3-py3-none-any.whl (26 kB)\n",
            "Downloading jpype1-1.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (494 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m494.1/494.1 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: JPype1, jaydebeapi\n",
            "Successfully installed JPype1-1.5.2 jaydebeapi-1.2.3\n"
          ]
        }
      ],
      "source": [
        "# Install dependencies\n",
        "!apt-get install openjdk-8-jdk -qq > /dev/null\n",
        "!pip install jaydebeapi\n",
        "\n",
        "# Download UCanAccess from a reliable mirror\n",
        "#https://downloads.sourceforge.net/project/ucanaccess/UCanAccess-5.0.1-bin.zip\n",
        "#Upload UCanAccess-5.0.1.bin.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qSwfRpsCNuG8"
      },
      "outputs": [],
      "source": [
        "!unzip -q /UCanAccess-5.0.1.bin.zip\n",
        "\n",
        "# Move required JAR files to current directory\n",
        "!mv /content/UCanAccess-5.0.1.bin/ucanaccess-5.0.1.jar ./\n",
        "!mv /content/UCanAccess-5.0.1.bin/lib/*.jar ./"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EInxwUCcNuJT",
        "outputId": "2941013e-bfe5-4198-f5d0-b806c2675128"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "commons-lang3-3.8.1.jar  hsqldb-2.5.0.jar    ucanaccess-5.0.1.jar\n",
            "commons-logging-1.2.jar  jackcess-3.0.1.jar\n"
          ]
        }
      ],
      "source": [
        "# List downloaded JAR files\n",
        "!ls *.jar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "1U63vUuWNuMC",
        "outputId": "fc672c1b-c651-4c49-b0f1-be4bb29d8d4f"
      },
      "outputs": [
        {
          "ename": "net.ucanaccess.jdbc.UcanaccessSQLException",
          "evalue": "net.ucanaccess.jdbc.UcanaccessSQLException: UCAExc:::5.0.1 given file does not exist: /Versand_19_DRG_PatKreis_2021.accdb",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mjava.io.FileNotFoundException\u001b[0m             Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/_jpype.cpython-311-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36morg.jpype.Reflector0.callMethod\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mjava.io.FileNotFoundException\u001b[0m: java.io.FileNotFoundException: given file does not exist: /Versand_19_DRG_PatKreis_2021.accdb",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/_jpype.cpython-311-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36morg.jpype.Reflector0.callMethod\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mException\u001b[0m: Java Exception",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mnet.ucanaccess.jdbc.UcanaccessSQLException\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-f9f78e3639ad>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Connect to database\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m conn = jaydebeapi.connect(\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;34m\"net.ucanaccess.jdbc.UcanaccessDriver\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;34mf\"jdbc:ucanaccess://{db_path}\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/jaydebeapi/__init__.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(jclassname, url, driver_args, jars, libs)\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[0mlibs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m     \u001b[0mjconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_jdbc_connect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjclassname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdriver_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mConnection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjconn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_converters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/jaydebeapi/__init__.py\u001b[0m in \u001b[0;36m_jdbc_connect_jpype\u001b[0;34m(jclassname, url, driver_args, jars, libs)\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0mdargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdriver_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mjpype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDriverManager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetConnection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mdargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_get_classpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mnet.ucanaccess.jdbc.UcanaccessSQLException\u001b[0m: net.ucanaccess.jdbc.UcanaccessSQLException: UCAExc:::5.0.1 given file does not exist: /Versand_19_DRG_PatKreis_2021.accdb"
          ]
        }
      ],
      "source": [
        "import jaydebeapi\n",
        "import glob\n",
        "\n",
        "# Get all JAR files\n",
        "jars = glob.glob(\"*.jar\")\n",
        "\n",
        "# Update with your actual file path\n",
        "db_path = \"/Versand_19_DRG_PatKreis_2021.accdb\"\n",
        "\n",
        "# Connect to database\n",
        "conn = jaydebeapi.connect(\n",
        "    \"net.ucanaccess.jdbc.UcanaccessDriver\",\n",
        "    f\"jdbc:ucanaccess://{db_path}\",\n",
        "    jars=jars\n",
        ")\n",
        "\n",
        "# Create cursor\n",
        "cursor = conn.cursor()\n",
        "\n",
        "# REPLACE 'YourTable' with your actual table name\n",
        "table_name = \"Versand_19_DRG_PatKreis_2021\"  # ⚠️ Change this to your table name!\n",
        "\n",
        "try:\n",
        "    # Get first 5 rows\n",
        "    cursor.execute(f\"SELECT TOP 5 * FROM `{table_name}`\")  # Use backticks for table names with spaces\n",
        "\n",
        "    # Get column names\n",
        "    columns = [desc[0] for desc in cursor.description]\n",
        "    print(\"Columns:\", columns)\n",
        "\n",
        "    # Get rows\n",
        "    rows = cursor.fetchall()\n",
        "    print(\"\\nFirst 5 rows:\")\n",
        "    for row in rows:\n",
        "        print(row)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error: {e}\")\n",
        "    print(\"Try using square brackets for table names with spaces: [Table Name]\")\n",
        "\n",
        "finally:\n",
        "    cursor.close()\n",
        "    conn.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lhuK6u8rUVcx"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# State mapping dictionary based on first 2 digits of Regionalschlüssel\n",
        "state_mapping = {\n",
        "    '01': 'Schleswig-Holstein',\n",
        "    '02': 'Hamburg',\n",
        "    '03': 'Niedersachsen',\n",
        "    '04': 'Bremen',\n",
        "    '05': 'Nordrhein-Westfalen',\n",
        "    '06': 'Hessen',\n",
        "    '07': 'Rheinland-Pfalz',\n",
        "    '08': 'Baden-Württemberg',\n",
        "    '09': 'Bayern',\n",
        "    '10': 'Saarland',\n",
        "    '11': 'Berlin',\n",
        "    '12': 'Brandenburg',\n",
        "    '13': 'Mecklenburg-Vorpommern',\n",
        "    '14': 'Sachsen',\n",
        "    '15': 'Sachsen-Anhalt',\n",
        "    '16': 'Thüringen'\n",
        "}\n",
        "\n",
        "# Read the Excel file\n",
        "file_path = '/dsb_19_drg_ag_kreis_2021.xlsx'\n",
        "df_sa40 = pd.read_excel(file_path, sheet_name='SA 40 2021')\n",
        "\n",
        "# Extract state code from Regionalschlüssel\n",
        "df_sa40['Regionalschlüssel'] = df_sa40['Regionalschlüssel'].astype(str).str.zfill(5)\n",
        "df_sa40['State_Code'] = df_sa40['Regionalschlüssel'].str[:2]\n",
        "\n",
        "# Map state codes to state names\n",
        "df_sa40['Bundesland'] = df_sa40['State_Code'].map(state_mapping)\n",
        "\n",
        "# Clean up temporary column\n",
        "df_sa40 = df_sa40.drop('State_Code', axis=1)\n",
        "\n",
        "# Save to new Excel file with both sheets\n",
        "with pd.ExcelWriter('updated_dsb_19_drg_ag_kreis_2021.xlsx') as writer:\n",
        "    # Save modified SA 40 2021 sheet\n",
        "    df_sa40.to_excel(writer, sheet_name='SA 40 2021', index=False)\n",
        "\n",
        "    # Save original DSB_drg 2021 sheet unchanged\n",
        "    df_dsb = pd.read_excel(file_path, sheet_name='DSB_drg 2021')\n",
        "    df_dsb.to_excel(writer, sheet_name='DSB_drg 2021', index=False)\n",
        "\n",
        "print(\"File saved as 'updated_dsb_19_drg_ag_kreis_2021.xlsx'\")\n",
        "print(\"Added 'Bundesland' column to the SA 40 2021 sheet\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vMdMFFxUVfC",
        "outputId": "9ce42d4d-7867-4f16-a739-5c723885bc82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File saved as 'updated_dsb_19_drg_ag_kreis_2022.xlsx'\n",
            "Added 'Bundesland' column to the SA 40 2022 sheet\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# State mapping dictionary based on first 2 digits of Regionalschlüssel\n",
        "state_mapping = {\n",
        "    '01': 'Schleswig-Holstein',\n",
        "    '02': 'Hamburg',\n",
        "    '03': 'Niedersachsen',\n",
        "    '04': 'Bremen',\n",
        "    '05': 'Nordrhein-Westfalen',\n",
        "    '06': 'Hessen',\n",
        "    '07': 'Rheinland-Pfalz',\n",
        "    '08': 'Baden-Württemberg',\n",
        "    '09': 'Bayern',\n",
        "    '10': 'Saarland',\n",
        "    '11': 'Berlin',\n",
        "    '12': 'Brandenburg',\n",
        "    '13': 'Mecklenburg-Vorpommern',\n",
        "    '14': 'Sachsen',\n",
        "    '15': 'Sachsen-Anhalt',\n",
        "    '16': 'Thüringen'\n",
        "}\n",
        "\n",
        "# Read the Excel file\n",
        "file_path = '/dsb_19_drg_ag_kreis_2022.xlsx'\n",
        "df_sa40 = pd.read_excel(file_path, sheet_name='SA 40 2022')\n",
        "\n",
        "# Convert Regionalschlüssel to string and pad with zeros to ensure 5-digit format\n",
        "df_sa40['Regionalschlüssel'] = df_sa40['Regionalschlüssel'].astype(str).str.zfill(5)\n",
        "\n",
        "# Extract state code from Regionalschlüssel\n",
        "df_sa40['State_Code'] = df_sa40['Regionalschlüssel'].str[:2]\n",
        "\n",
        "# Map state codes to state names\n",
        "df_sa40['Bundesland'] = df_sa40['State_Code'].map(state_mapping)\n",
        "\n",
        "# Clean up temporary column\n",
        "df_sa40 = df_sa40.drop('State_Code', axis=1)\n",
        "\n",
        "# Save to new Excel file with both sheets\n",
        "with pd.ExcelWriter('updated_dsb_19_drg_ag_kreis_2022.xlsx') as writer:\n",
        "    # Save modified SA 40 2022 sheet\n",
        "    df_sa40.to_excel(writer, sheet_name='SA 40 2022', index=False)\n",
        "\n",
        "    # Save original DSB_drg 2022 sheet unchanged\n",
        "    df_dsb = pd.read_excel(file_path, sheet_name='DSB_drg 2022')\n",
        "    df_dsb.to_excel(writer, sheet_name='DSB_drg 2022', index=False)\n",
        "\n",
        "print(\"File saved as 'updated_dsb_19_drg_ag_kreis_2022.xlsx'\")\n",
        "print(\"Added 'Bundesland' column to the SA 40 2022 sheet\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pow1ffBdVZhZ",
        "outputId": "dae3bacf-8e86-48c5-9e42-c17526479aeb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Columns after skipping first row: ['MDC – Major Diagnostic Categories', 'DRG Zuteilung', 'DRGs gesamt (zum Ansehen anklicken)', 'Fachabteilung', 'Sekundär']\n",
            "DRG: A01A => MDC: Prä – Prä-MDC, Fachabteilung: Notfallaufnahme, Sekundär: Intensivmedizin\n",
            "DRG: B61B => MDC: Prä – Prä-MDC, Fachabteilung: Notfallaufnahme, Sekundär: Intensivmedizin\n",
            "DRG: F02B => MDC: 05 – Krankheiten und Störungen des Kreislaufsystems, Fachabteilung: Kardiologi, Sekundär: Herzchirurgie\n",
            "DRG: 801A => MDC: 24 – Sonstige DRGs, Fachabteilung: Diverse Fachabteilungen, Sekundär: Fachabteilungen\n",
            "DRG: G01Z => MDC: 06 – Krankheiten und Störungen der Verdauungsorgane, Fachabteilung: Gastroenterologie, Sekundär: Viszeralchirurgie\n",
            "DRG: Z01A => MDC: 23 – Faktoren, die den Gesundheitszustand beeinflussen, und andere Inanspruchnahme des Gesundheitswesens, Fachabteilung: Allgemeinmedizin / Sozialmedizin, Sekundär: Sozialmedizin\n",
            "\n",
            "Total mapping ranges processed: 30\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Read the Excel mapping file, skipping the first empty row\n",
        "mapping_df = pd.read_excel('/DRG_Fachabteilung Cluster.xlsx',\n",
        "                           sheet_name='Sheet1',\n",
        "                           skiprows=1)\n",
        "\n",
        "# Verify we have the correct columns\n",
        "print(\"Columns after skipping first row:\", mapping_df.columns.tolist())\n",
        "\n",
        "# Preprocess the mapping data\n",
        "mapping_data = []\n",
        "for _, row in mapping_df.iterrows():\n",
        "    # Check if we have the expected columns\n",
        "    if 'DRG Zuteilung' not in row:\n",
        "        # If column name changed, try to find similar column\n",
        "        drg_col = next((col for col in mapping_df.columns if 'DRG' in col and 'Zuteilung' in col), None)\n",
        "        if drg_col:\n",
        "            ranges = str(row[drg_col])\n",
        "        else:\n",
        "            print(\"Could not find DRG Zuteilung column\")\n",
        "            break\n",
        "    else:\n",
        "        ranges = str(row['DRG Zuteilung'])\n",
        "\n",
        "    # Skip rows with missing range data\n",
        "    if ranges == 'nan' or not ranges.strip():\n",
        "        continue\n",
        "\n",
        "    # Process each range\n",
        "    for range_str in ranges.split(';'):\n",
        "        range_str = range_str.strip()\n",
        "        if '–' in range_str:\n",
        "            parts = range_str.split('–')\n",
        "            if len(parts) == 2:\n",
        "                start, end = [s.strip() for s in parts]\n",
        "                mapping_data.append({\n",
        "                    'start': start,\n",
        "                    'end': end,\n",
        "                    'MDC': row.iloc[0],  # First column is MDC\n",
        "                    'Fachabteilung': row['Fachabteilung'] if 'Fachabteilung' in row else np.nan,\n",
        "                    'Sekundär': row['Sekundär'] if 'Sekundär' in row else np.nan\n",
        "                })\n",
        "            else:\n",
        "                print(f\"Skipping invalid range format: {range_str}\")\n",
        "\n",
        "# Create a function to map individual DRG codes\n",
        "def map_drg(drg_code):\n",
        "    if pd.isna(drg_code) or not drg_code:\n",
        "        return np.nan, np.nan, np.nan\n",
        "\n",
        "    drg_code = str(drg_code).strip().upper()\n",
        "\n",
        "    for item in mapping_data:\n",
        "        start = item['start']\n",
        "        end = item['end']\n",
        "\n",
        "        # Handle different DRG formats\n",
        "        if drg_code[0].isalpha() and start[0].isalpha():\n",
        "            # Alphanumeric format (e.g., A01A)\n",
        "            if start <= drg_code <= end:\n",
        "                return item['MDC'], item['Fachabteilung'], item['Sekundär']\n",
        "        else:\n",
        "            # Numeric format (e.g., 801A)\n",
        "            try:\n",
        "                # Extract numeric parts\n",
        "                drg_num = int(drg_code[:3])\n",
        "                start_num = int(start[:3])\n",
        "                end_num = int(end[:3])\n",
        "\n",
        "                if start_num <= drg_num <= end_num:\n",
        "                    return item['MDC'], item['Fachabteilung'], item['Sekundär']\n",
        "            except:\n",
        "                continue\n",
        "    return np.nan, np.nan, np.nan\n",
        "\n",
        "# Test with sample DRG codes\n",
        "test_codes = ['A01A', 'B61B', 'F02B', '801A', 'G01Z', 'Z01A']\n",
        "for code in test_codes:\n",
        "    mdc, fach, sek = map_drg(code)\n",
        "    print(f\"DRG: {code} => MDC: {mdc}, Fachabteilung: {fach}, Sekundär: {sek}\")\n",
        "\n",
        "print(f\"\\nTotal mapping ranges processed: {len(mapping_data)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zA_HLKwtVZjw"
      },
      "outputs": [],
      "source": [
        "import jaydebeapi\n",
        "import glob\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "\n",
        "# Step 1: Load and process the DRG mapping Excel file\n",
        "# --------------------------------------------------\n",
        "def load_drg_mapping():\n",
        "    mapping_df = pd.read_excel('/DRG_Fachabteilung Cluster.xlsx',\n",
        "                               sheet_name='Sheet1',\n",
        "                               skiprows=1)\n",
        "\n",
        "    mapping_data = []\n",
        "    for _, row in mapping_df.iterrows():\n",
        "        range_str = str(row.iloc[1])  # Second column is DRG Zuteilung\n",
        "        if range_str == 'nan' or not range_str.strip():\n",
        "            continue\n",
        "\n",
        "        for sub_range in range_str.split(';'):\n",
        "            sub_range = sub_range.strip()\n",
        "            if '–' in sub_range:\n",
        "                parts = sub_range.split('–')\n",
        "                if len(parts) == 2:\n",
        "                    start, end = [s.strip() for s in parts]\n",
        "                    mapping_data.append({\n",
        "                        'start': start,\n",
        "                        'end': end,\n",
        "                        'MDC': str(row.iloc[0]) if pd.notnull(row.iloc[0]) else \"\",\n",
        "                        'Fachabteilung': str(row.iloc[3]) if pd.notnull(row.iloc[3]) else \"\",\n",
        "                        'Sekundär': str(row.iloc[4]) if pd.notnull(row.iloc[4]) else \"\"\n",
        "                    })\n",
        "    return mapping_data\n",
        "\n",
        "# Create optimized mapping dictionary\n",
        "def create_mapping_dict(mapping_data):\n",
        "    mapping_dict = {}\n",
        "\n",
        "    # Create ranges for numeric DRGs\n",
        "    for item in mapping_data:\n",
        "        try:\n",
        "            # Handle numeric ranges (e.g., 801A)\n",
        "            if item['start'][0].isdigit():\n",
        "                start_num = int(item['start'][:3])\n",
        "                end_num = int(item['end'][:3])\n",
        "                for num in range(start_num, end_num + 1):\n",
        "                    # Create all possible suffixes for this numeric base\n",
        "                    base = str(num).zfill(3)\n",
        "                    for suffix in ['', 'A', 'B', 'C', 'D', 'E', 'Z']:\n",
        "                        code = base + suffix\n",
        "                        mapping_dict[code] = (\n",
        "                            item['MDC'],\n",
        "                            item['Fachabteilung'],\n",
        "                            item['Sekundär']\n",
        "                        )\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "    # Create ranges for alpha DRGs\n",
        "    for item in mapping_data:\n",
        "        try:\n",
        "            # Handle alpha ranges (e.g., A01A)\n",
        "            if item['start'][0].isalpha():\n",
        "                start_base = item['start'][:3]\n",
        "                end_base = item['end'][:3]\n",
        "\n",
        "                # Generate all possible codes in range\n",
        "                current = start_base\n",
        "                while current <= end_base:\n",
        "                    # Add with and without suffix\n",
        "                    mapping_dict[current] = (\n",
        "                        item['MDC'],\n",
        "                        item['Fachabteilung'],\n",
        "                        item['Sekundär']\n",
        "                    )\n",
        "\n",
        "                    # Also add common suffixes\n",
        "                    for suffix in ['A', 'B', 'C', 'D', 'E', 'Z']:\n",
        "                        mapping_dict[current + suffix] = (\n",
        "                            item['MDC'],\n",
        "                            item['Fachabteilung'],\n",
        "                            item['Sekundär']\n",
        "                        )\n",
        "\n",
        "                    # Increment the code (A01 -> A02, etc.)\n",
        "                    prefix = current[0]\n",
        "                    num = int(current[1:3]) + 1\n",
        "                    current = f\"{prefix}{num:02d}\"\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "    return mapping_dict\n",
        "\n",
        "# Load the mapping data\n",
        "mapping_data = load_drg_mapping()\n",
        "mapping_dict = create_mapping_dict(mapping_data)\n",
        "print(f\"Created mapping dictionary with {len(mapping_dict)} entries\")\n",
        "\n",
        "# Find longest MDC value for debugging\n",
        "max_mdc_len = 0\n",
        "max_fach_len = 0\n",
        "max_sek_len = 0\n",
        "\n",
        "for key, value in mapping_dict.items():\n",
        "    # Ensure all values are strings\n",
        "    mdc_str = str(value[0])\n",
        "    fach_str = str(value[1])\n",
        "    sek_str = str(value[2])\n",
        "\n",
        "    if len(mdc_str) > max_mdc_len:\n",
        "        max_mdc_len = len(mdc_str)\n",
        "    if len(fach_str) > max_fach_len:\n",
        "        max_fach_len = len(fach_str)\n",
        "    if len(sek_str) > max_sek_len:\n",
        "        max_sek_len = len(sek_str)\n",
        "\n",
        "print(f\"Max MDC length: {max_mdc_len}\")\n",
        "print(f\"Max Fachabteilung length: {max_fach_len}\")\n",
        "print(f\"Max Sekundär length: {max_sek_len}\")\n",
        "\n",
        "# Step 2: Connect to the Access database\n",
        "# --------------------------------------\n",
        "jars = glob.glob(\"*.jar\")\n",
        "db_path = \"/Versand_19_DRG_PatKreis_2021.accdb\"\n",
        "\n",
        "# Function to create a new connection\n",
        "def create_connection():\n",
        "    return jaydebeapi.connect(\n",
        "        \"net.ucanaccess.jdbc.UcanaccessDriver\",\n",
        "        f\"jdbc:ucanaccess://{db_path}\",\n",
        "        jars=jars\n",
        "    )\n",
        "\n",
        "# Create initial connection\n",
        "conn = create_connection()\n",
        "cursor = conn.cursor()\n",
        "\n",
        "# Step 3: Create new table with enhanced columns\n",
        "# ---------------------------------------------\n",
        "table_name = \"Versand_19_DRG_PatKreis_2021\"\n",
        "new_table_name = \"Enhanced_DRG_Data\"\n",
        "\n",
        "try:\n",
        "    # Drop existing table if exists\n",
        "    cursor.execute(f\"DROP TABLE IF EXISTS `{new_table_name}`\")\n",
        "    conn.commit()\n",
        "\n",
        "    # Create new table with larger columns\n",
        "    cursor.execute(f\"\"\"\n",
        "        CREATE TABLE `{new_table_name}` (\n",
        "            pat_ags5 VARCHAR(10),\n",
        "            drg VARCHAR(10),\n",
        "            typ_alter VARCHAR(10),\n",
        "            patient INTEGER,\n",
        "            MDC VARCHAR(255),\n",
        "            Fachabteilung VARCHAR(255),\n",
        "            Sekundär VARCHAR(255)\n",
        "        )\n",
        "    \"\"\")\n",
        "    conn.commit()\n",
        "    print(\"Created new table with larger columns (255 characters)\")\n",
        "\n",
        "    # Get total row count\n",
        "    cursor.execute(f\"SELECT COUNT(*) FROM `{table_name}`\")\n",
        "    total_rows = cursor.fetchone()[0]\n",
        "    print(f\"Total rows to process: {total_rows:,}\")\n",
        "\n",
        "    # Get all rows using a server-side cursor\n",
        "    cursor.execute(f\"SELECT pat_ags5, drg, typ_alter, patient FROM `{table_name}`\")\n",
        "\n",
        "    # Process in smaller batches\n",
        "    batch_size = 10000  # Reduced from 50,000 to 10,000\n",
        "    processed = 0\n",
        "    batch_count = 0\n",
        "\n",
        "    # Create new progress bar\n",
        "    pbar = tqdm(total=total_rows, desc=\"Processing data\")\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            # Fetch batch of rows with retry mechanism\n",
        "            rows = None\n",
        "            for attempt in range(3):  # Try up to 3 times\n",
        "                try:\n",
        "                    rows = cursor.fetchmany(batch_size)\n",
        "                    break\n",
        "                except jaydebeapi.Error as fetch_error:\n",
        "                    print(f\"Fetch error (attempt {attempt+1}/3): {fetch_error}\")\n",
        "                    # Reconnect\n",
        "                    cursor.close()\n",
        "                    conn.close()\n",
        "                    time.sleep(2)  # Wait before reconnecting\n",
        "                    conn = create_connection()\n",
        "                    cursor = conn.cursor()\n",
        "                    # Re-execute the query\n",
        "                    cursor.execute(f\"SELECT pat_ags5, drg, typ_alter, patient FROM `{table_name}`\")\n",
        "                    # Skip already processed rows\n",
        "                    for _ in range(processed):\n",
        "                        cursor.fetchone()\n",
        "\n",
        "            if not rows:\n",
        "                break\n",
        "\n",
        "            # Process batch\n",
        "            enhanced_batch = []\n",
        "            for row in rows:\n",
        "                pat_ags5, drg, typ_alter, patient = row\n",
        "                # Clean and standardize DRG code\n",
        "                clean_drg = str(drg).strip().upper()\n",
        "\n",
        "                # Get mapping from dictionary\n",
        "                mapping = mapping_dict.get(clean_drg, (None, None, None))\n",
        "\n",
        "                # Convert None values to empty strings\n",
        "                mdc_val = mapping[0] if mapping[0] is not None else \"\"\n",
        "                fach_val = mapping[1] if mapping[1] is not None else \"\"\n",
        "                sek_val = mapping[2] if mapping[2] is not None else \"\"\n",
        "\n",
        "                # Ensure all values are strings and truncate\n",
        "                mdc_val = str(mdc_val)[:254]\n",
        "                fach_val = str(fach_val)[:254]\n",
        "                sek_val = str(sek_val)[:254]\n",
        "\n",
        "                # Ensure patient is integer\n",
        "                try:\n",
        "                    patient_val = int(patient) if patient is not None else 0\n",
        "                except:\n",
        "                    patient_val = 0\n",
        "\n",
        "                # Ensure all other values are strings\n",
        "                pat_ags5_val = str(pat_ags5)[:9] if pat_ags5 is not None else \"\"\n",
        "                drg_val = clean_drg[:9]\n",
        "                typ_alter_val = str(typ_alter)[:9] if typ_alter is not None else \"\"\n",
        "\n",
        "                enhanced_batch.append((\n",
        "                    pat_ags5_val,\n",
        "                    drg_val,\n",
        "                    typ_alter_val,\n",
        "                    patient_val,\n",
        "                    mdc_val,\n",
        "                    fach_val,\n",
        "                    sek_val\n",
        "                ))\n",
        "\n",
        "            # Insert batch into new table\n",
        "            if enhanced_batch:\n",
        "                insert_sql = f\"\"\"\n",
        "                    INSERT INTO `{new_table_name}`\n",
        "                    (pat_ags5, drg, typ_alter, patient, MDC, Fachabteilung, Sekundär)\n",
        "                    VALUES (?, ?, ?, ?, ?, ?, ?)\n",
        "                \"\"\"\n",
        "                try:\n",
        "                    cursor.executemany(insert_sql, enhanced_batch)\n",
        "                    conn.commit()\n",
        "                except Exception as batch_error:\n",
        "                    print(f\"Error in batch: {batch_error}\")\n",
        "                    # Try inserting row by row to identify problematic row\n",
        "                    for i, row_data in enumerate(enhanced_batch):\n",
        "                        try:\n",
        "                            cursor.execute(insert_sql, row_data)\n",
        "                            conn.commit()\n",
        "                        except Exception as row_error:\n",
        "                            print(f\"Error in row {i}: {row_data}\")\n",
        "                            print(f\"Row error: {row_error}\")\n",
        "                            # Skip problematic row\n",
        "                    conn.rollback()\n",
        "\n",
        "            processed += len(rows)\n",
        "            batch_count += 1\n",
        "            pbar.update(len(rows))\n",
        "\n",
        "            # Commit progress periodically\n",
        "            if batch_count % 10 == 0:\n",
        "                print(f\"Processed {processed:,} rows ({processed/total_rows:.1%})\")\n",
        "\n",
        "        except Exception as batch_exception:\n",
        "            print(f\"Error processing batch: {batch_exception}\")\n",
        "            # Reconnect and continue\n",
        "            cursor.close()\n",
        "            conn.close()\n",
        "            conn = create_connection()\n",
        "            cursor = conn.cursor()\n",
        "            # Re-execute the query\n",
        "            cursor.execute(f\"SELECT pat_ags5, drg, typ_alter, patient FROM `{table_name}`\")\n",
        "            # Skip already processed rows\n",
        "            for _ in range(processed):\n",
        "                cursor.fetchone()\n",
        "\n",
        "    pbar.close()\n",
        "    print(f\"\\nSuccessfully processed {processed:,} rows\")\n",
        "    print(f\"Created enhanced table: {new_table_name}\")\n",
        "\n",
        "    # Verify results\n",
        "    cursor.execute(f\"SELECT COUNT(*) FROM `{new_table_name}`\")\n",
        "    new_count = cursor.fetchone()[0]\n",
        "    print(f\"New table row count: {new_count:,}\")\n",
        "\n",
        "    # Show sample of added data\n",
        "    cursor.execute(f\"\"\"\n",
        "        SELECT drg, MDC, Fachabteilung, Sekundär\n",
        "        FROM `{new_table_name}`\n",
        "        WHERE LEN(MDC) > 100\n",
        "        LIMIT 5\n",
        "    \"\"\")\n",
        "    long_mdc_rows = cursor.fetchall()\n",
        "    if long_mdc_rows:\n",
        "        print(\"\\nSample long MDC mappings:\")\n",
        "        for row in long_mdc_rows:\n",
        "            print(f\"DRG: {row[0]}, MDC length: {len(row[1])}\")\n",
        "    else:\n",
        "        print(\"\\nNo MDC values longer than 100 characters found\")\n",
        "\n",
        "    # Show random sample\n",
        "    cursor.execute(f\"\"\"\n",
        "        SELECT TOP 5 drg, MDC, Fachabteilung, Sekundär\n",
        "        FROM `{new_table_name}`\n",
        "        WHERE MDC IS NOT NULL AND MDC != ''\n",
        "    \"\"\")\n",
        "    print(\"\\nRandom sample mappings:\")\n",
        "    for row in cursor.fetchall():\n",
        "        print(row)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "    conn.rollback()\n",
        "\n",
        "finally:\n",
        "    cursor.close()\n",
        "    conn.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FgZ-Bj9UaTYF",
        "outputId": "021acffb-1d47-41b2-e7cb-3e05a860e595"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total rows to process: 2,761,513\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Processing data:  43%|████▎     | 1180000/2761513 [37:03<49:40, 530.67it/s]  \n",
            "\n",
            "Aggregating by state and DRG:   1%|          | 21892/2761513 [02:37<5:27:46, 139.30it/s]\u001b[A\n",
            "Aggregating by state and DRG:   1%|          | 21892/2761513 [03:08<6:32:42, 116.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Created aggregated table with 21,892 rows\n",
            "Created DRG mapping dictionary with 13594 entries\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Adding MDC mapping: 100%|██████████| 21892/21892 [02:04<00:00, 175.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Created final table with 21,892 rows\n",
            "Saved results to State_DRG_Analysis.xlsx\n",
            "\n",
            "Sample of final analysis:\n",
            "                state   drg                 MDC            Fachabteilung  \\\n",
            "0  Schleswig-Holstein  801A  24 – Sonstige DRGs  Diverse Fachabteilungen   \n",
            "1  Schleswig-Holstein  801B  24 – Sonstige DRGs  Diverse Fachabteilungen   \n",
            "2  Schleswig-Holstein  801C  24 – Sonstige DRGs  Diverse Fachabteilungen   \n",
            "3  Schleswig-Holstein  801D  24 – Sonstige DRGs  Diverse Fachabteilungen   \n",
            "4  Schleswig-Holstein  801E  24 – Sonstige DRGs  Diverse Fachabteilungen   \n",
            "5  Schleswig-Holstein  802A  24 – Sonstige DRGs  Diverse Fachabteilungen   \n",
            "6  Schleswig-Holstein  802B  24 – Sonstige DRGs  Diverse Fachabteilungen   \n",
            "7  Schleswig-Holstein  802C  24 – Sonstige DRGs  Diverse Fachabteilungen   \n",
            "8  Schleswig-Holstein  802D  24 – Sonstige DRGs  Diverse Fachabteilungen   \n",
            "9  Schleswig-Holstein  863Z  24 – Sonstige DRGs  Diverse Fachabteilungen   \n",
            "\n",
            "          Sekundär  total_patients  \n",
            "0  Fachabteilungen              25  \n",
            "1  Fachabteilungen             143  \n",
            "2  Fachabteilungen              91  \n",
            "3  Fachabteilungen             433  \n",
            "4  Fachabteilungen             130  \n",
            "5  Fachabteilungen              96  \n",
            "6  Fachabteilungen              59  \n",
            "7  Fachabteilungen              88  \n",
            "8  Fachabteilungen              40  \n",
            "9  Fachabteilungen              12  \n"
          ]
        }
      ],
      "source": [
        "import jaydebeapi\n",
        "import glob\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "# State mapping dictionary\n",
        "state_mapping = {\n",
        "    '01': 'Schleswig-Holstein',\n",
        "    '02': 'Hamburg',\n",
        "    '03': 'Niedersachsen',\n",
        "    '04': 'Bremen',\n",
        "    '05': 'Nordrhein-Westfalen',\n",
        "    '06': 'Hessen',\n",
        "    '07': 'Rheinland-Pfalz',\n",
        "    '08': 'Baden-Württemberg',\n",
        "    '09': 'Bayern',\n",
        "    '10': 'Saarland',\n",
        "    '11': 'Berlin',\n",
        "    '12': 'Brandenburg',\n",
        "    '13': 'Mecklenburg-Vorpommern',\n",
        "    '14': 'Sachsen',\n",
        "    '15': 'Sachsen-Anhalt',\n",
        "    '16': 'Thüringen'\n",
        "}\n",
        "\n",
        "# Step 1: Connect to database and create state-aggregated table\n",
        "# ------------------------------------------------------------\n",
        "jars = glob.glob(\"*.jar\")\n",
        "db_path = \"/Versand_19_DRG_PatKreis_2021.accdb\"\n",
        "\n",
        "conn = jaydebeapi.connect(\n",
        "    \"net.ucanaccess.jdbc.UcanaccessDriver\",\n",
        "    f\"jdbc:ucanaccess://{db_path}\",\n",
        "    jars=jars\n",
        ")\n",
        "cursor = conn.cursor()\n",
        "\n",
        "# Create new aggregated table\n",
        "temp_table_name = \"State_DRG_Aggregation\"\n",
        "try:\n",
        "    # Create temporary table for state-level aggregation\n",
        "    cursor.execute(f\"DROP TABLE IF EXISTS `{temp_table_name}`\")\n",
        "    cursor.execute(f\"\"\"\n",
        "        CREATE TABLE `{temp_table_name}` (\n",
        "            state VARCHAR(50),\n",
        "            drg VARCHAR(10),\n",
        "            total_patients INTEGER\n",
        "        )\n",
        "    \"\"\")\n",
        "    conn.commit()\n",
        "\n",
        "    # Get total row count\n",
        "    cursor.execute(f\"SELECT COUNT(*) FROM Versand_19_DRG_PatKreis_2021\")\n",
        "    total_rows = cursor.fetchone()[0]\n",
        "    print(f\"Total rows to process: {total_rows:,}\")\n",
        "\n",
        "    # Process data in batches\n",
        "    batch_size = 50000\n",
        "    offset = 0\n",
        "    processed = 0\n",
        "\n",
        "    with tqdm(total=total_rows, desc=\"Aggregating by state and DRG\") as pbar:\n",
        "        while offset < total_rows:\n",
        "            # Get batch of data\n",
        "            cursor.execute(f\"\"\"\n",
        "                SELECT\n",
        "                    LEFT(pat_ags5, 2) AS state_code,\n",
        "                    drg,\n",
        "                    SUM(patient) AS total_patients\n",
        "                FROM Versand_19_DRG_PatKreis_2021\n",
        "                GROUP BY LEFT(pat_ags5, 2), drg\n",
        "                ORDER BY state_code, drg\n",
        "                OFFSET {offset} ROWS FETCH NEXT {batch_size} ROWS ONLY\n",
        "            \"\"\")\n",
        "            batch = cursor.fetchall()\n",
        "\n",
        "            if not batch:\n",
        "                break\n",
        "\n",
        "            # Insert into temp table\n",
        "            insert_sql = f\"\"\"\n",
        "                INSERT INTO `{temp_table_name}`\n",
        "                (state, drg, total_patients)\n",
        "                VALUES (?, ?, ?)\n",
        "            \"\"\"\n",
        "            for row in batch:\n",
        "                state_code, drg, patients = row\n",
        "                state_name = state_mapping.get(str(state_code), \"Unknown\")\n",
        "                cursor.execute(insert_sql, (state_name, drg, patients))\n",
        "\n",
        "            conn.commit()\n",
        "            offset += batch_size\n",
        "            processed += len(batch)\n",
        "            pbar.update(len(batch))\n",
        "\n",
        "    print(f\"\\nCreated aggregated table with {processed:,} rows\")\n",
        "\n",
        "    # Step 2: Load DRG mapping\n",
        "    # ------------------------\n",
        "    def load_drg_mapping():\n",
        "        mapping_df = pd.read_excel('/DRG_Fachabteilung Cluster.xlsx',\n",
        "                                   sheet_name='Sheet1',\n",
        "                                   skiprows=1)\n",
        "\n",
        "        mapping_data = []\n",
        "        for _, row in mapping_df.iterrows():\n",
        "            range_str = str(row.iloc[1])  # Second column is DRG Zuteilung\n",
        "            if range_str == 'nan' or not range_str.strip():\n",
        "                continue\n",
        "\n",
        "            for sub_range in range_str.split(';'):\n",
        "                sub_range = sub_range.strip()\n",
        "                if '–' in sub_range:\n",
        "                    parts = sub_range.split('–')\n",
        "                    if len(parts) == 2:\n",
        "                        start, end = [s.strip() for s in parts]\n",
        "                        mapping_data.append({\n",
        "                            'start': start,\n",
        "                            'end': end,\n",
        "                            'MDC': str(row.iloc[0]) if pd.notnull(row.iloc[0]) else \"\",\n",
        "                            'Fachabteilung': str(row.iloc[3]) if pd.notnull(row.iloc[3]) else \"\",\n",
        "                            'Sekundär': str(row.iloc[4]) if pd.notnull(row.iloc[4]) else \"\"\n",
        "                        })\n",
        "        return mapping_data\n",
        "\n",
        "    # Create optimized mapping dictionary\n",
        "    def create_mapping_dict(mapping_data):\n",
        "        mapping_dict = {}\n",
        "\n",
        "        # Create ranges for numeric DRGs\n",
        "        for item in mapping_data:\n",
        "            try:\n",
        "                # Handle numeric ranges (e.g., 801A)\n",
        "                if item['start'][0].isdigit():\n",
        "                    start_num = int(item['start'][:3])\n",
        "                    end_num = int(item['end'][:3])\n",
        "                    for num in range(start_num, end_num + 1):\n",
        "                        # Create all possible suffixes for this numeric base\n",
        "                        base = str(num).zfill(3)\n",
        "                        for suffix in ['', 'A', 'B', 'C', 'D', 'E', 'Z']:\n",
        "                            code = base + suffix\n",
        "                            mapping_dict[code] = (\n",
        "                                item['MDC'],\n",
        "                                item['Fachabteilung'],\n",
        "                                item['Sekundär']\n",
        "                            )\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "        # Create ranges for alpha DRGs\n",
        "        for item in mapping_data:\n",
        "            try:\n",
        "                # Handle alpha ranges (e.g., A01A)\n",
        "                if item['start'][0].isalpha():\n",
        "                    start_base = item['start'][:3]\n",
        "                    end_base = item['end'][:3]\n",
        "\n",
        "                    # Generate all possible codes in range\n",
        "                    current = start_base\n",
        "                    while current <= end_base:\n",
        "                        # Add with and without suffix\n",
        "                        mapping_dict[current] = (\n",
        "                            item['MDC'],\n",
        "                            item['Fachabteilung'],\n",
        "                            item['Sekundär']\n",
        "                        )\n",
        "\n",
        "                        # Also add common suffixes\n",
        "                        for suffix in ['A', 'B', 'C', 'D', 'E', 'Z']:\n",
        "                            mapping_dict[current + suffix] = (\n",
        "                                item['MDC'],\n",
        "                                item['Fachabteilung'],\n",
        "                                item['Sekundär']\n",
        "                            )\n",
        "\n",
        "                        # Increment the code (A01 -> A02, etc.)\n",
        "                        prefix = current[0]\n",
        "                        num = int(current[1:3]) + 1\n",
        "                        current = f\"{prefix}{num:02d}\"\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "        return mapping_dict\n",
        "\n",
        "    # Load the mapping data\n",
        "    mapping_data = load_drg_mapping()\n",
        "    mapping_dict = create_mapping_dict(mapping_data)\n",
        "    print(f\"Created DRG mapping dictionary with {len(mapping_dict)} entries\")\n",
        "\n",
        "    # Step 3: Create final table with MDC mapping\n",
        "    # -------------------------------------------\n",
        "    final_table_name = \"Final_State_DRG_Analysis\"\n",
        "\n",
        "    cursor.execute(f\"DROP TABLE IF EXISTS `{final_table_name}`\")\n",
        "    cursor.execute(f\"\"\"\n",
        "        CREATE TABLE `{final_table_name}` (\n",
        "            state VARCHAR(50),\n",
        "            drg VARCHAR(10),\n",
        "            MDC VARCHAR(255),\n",
        "            Fachabteilung VARCHAR(255),\n",
        "            Sekundär VARCHAR(255),\n",
        "            total_patients INTEGER\n",
        "        )\n",
        "    \"\"\")\n",
        "    conn.commit()\n",
        "\n",
        "    # Get aggregated data\n",
        "    cursor.execute(f\"SELECT state, drg, total_patients FROM `{temp_table_name}`\")\n",
        "    aggregated_data = cursor.fetchall()\n",
        "\n",
        "    # Process aggregated data and add MDC mapping\n",
        "    for state, drg, patients in tqdm(aggregated_data, desc=\"Adding MDC mapping\"):\n",
        "        clean_drg = str(drg).strip().upper()\n",
        "        mapping = mapping_dict.get(clean_drg, (\"Unknown\", \"Unknown\", \"Unknown\"))\n",
        "\n",
        "        insert_sql = f\"\"\"\n",
        "            INSERT INTO `{final_table_name}`\n",
        "            (state, drg, MDC, Fachabteilung, Sekundär, total_patients)\n",
        "            VALUES (?, ?, ?, ?, ?, ?)\n",
        "        \"\"\"\n",
        "        cursor.execute(insert_sql, (\n",
        "            state,\n",
        "            clean_drg,\n",
        "            str(mapping[0])[:254],\n",
        "            str(mapping[1])[:254],\n",
        "            str(mapping[2])[:254],\n",
        "            patients\n",
        "        ))\n",
        "\n",
        "    conn.commit()\n",
        "    print(f\"Created final table with {len(aggregated_data):,} rows\")\n",
        "\n",
        "    # Export to Excel\n",
        "    cursor.execute(f\"SELECT * FROM `{final_table_name}`\")\n",
        "    columns = [desc[0] for desc in cursor.description]\n",
        "    final_data = cursor.fetchall()\n",
        "\n",
        "    result_df = pd.DataFrame(final_data, columns=columns)\n",
        "    output_file = \"State_DRG_Analysis.xlsx\"\n",
        "    result_df.to_excel(output_file, index=False)\n",
        "    print(f\"Saved results to {output_file}\")\n",
        "\n",
        "    # Show sample\n",
        "    print(\"\\nSample of final analysis:\")\n",
        "    print(result_df.head(10))\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "    conn.rollback()\n",
        "\n",
        "finally:\n",
        "    cursor.close()\n",
        "    conn.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mnwfl8DTaTam",
        "outputId": "db72a490-d198-4488-dfa3-8885d73ef60d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Aggregating data by state and DRG...\n",
            "Aggregated into 21,892 state/DRG combinations\n",
            "Loading DRG mapping...\n",
            "Created DRG mapping with 1942 entries\n",
            "Creating final table...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing: 100%|██████████| 21892/21892 [01:55<00:00, 188.91it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Created final table with 21,892 rows\n",
            "Final table contains 21,892 rows\n",
            "\n",
            "Sample records:\n",
            "('Schleswig-Holstein', '801A', '24 – Sonstige DRGs', 'Diverse Fachabteilungen', 'Fachabteilungen', 25)\n",
            "('Schleswig-Holstein', '801B', '24 – Sonstige DRGs', 'Diverse Fachabteilungen', 'Fachabteilungen', 143)\n",
            "('Schleswig-Holstein', '801C', '24 – Sonstige DRGs', 'Diverse Fachabteilungen', 'Fachabteilungen', 91)\n",
            "('Schleswig-Holstein', '801D', '24 – Sonstige DRGs', 'Diverse Fachabteilungen', 'Fachabteilungen', 433)\n",
            "('Schleswig-Holstein', '801E', '24 – Sonstige DRGs', 'Diverse Fachabteilungen', 'Fachabteilungen', 130)\n",
            "('Schleswig-Holstein', '802A', '24 – Sonstige DRGs', 'Diverse Fachabteilungen', 'Fachabteilungen', 96)\n",
            "('Schleswig-Holstein', '802B', '24 – Sonstige DRGs', 'Diverse Fachabteilungen', 'Fachabteilungen', 59)\n",
            "('Schleswig-Holstein', '802C', '24 – Sonstige DRGs', 'Diverse Fachabteilungen', 'Fachabteilungen', 88)\n",
            "('Schleswig-Holstein', '802D', '24 – Sonstige DRGs', 'Diverse Fachabteilungen', 'Fachabteilungen', 40)\n",
            "('Schleswig-Holstein', '960Z', '-1 – Fehler-DRGs und sonstige DRGs', 'nan', 'nan', 6)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import jaydebeapi\n",
        "import glob\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "# State mapping dictionary\n",
        "state_mapping = {\n",
        "    '01': 'Schleswig-Holstein',\n",
        "    '02': 'Hamburg',\n",
        "    '03': 'Niedersachsen',\n",
        "    '04': 'Bremen',\n",
        "    '05': 'Nordrhein-Westfalen',\n",
        "    '06': 'Hessen',\n",
        "    '07': 'Rheinland-Pfalz',\n",
        "    '08': 'Baden-Württemberg',\n",
        "    '09': 'Bayern',\n",
        "    '10': 'Saarland',\n",
        "    '11': 'Berlin',\n",
        "    '12': 'Brandenburg',\n",
        "    '13': 'Mecklenburg-Vorpommern',\n",
        "    '14': 'Sachsen',\n",
        "    '15': 'Sachsen-Anhalt',\n",
        "    '16': 'Thüringen'\n",
        "}\n",
        "\n",
        "# Step 1: Connect to database\n",
        "jars = glob.glob(\"*.jar\")\n",
        "db_path = \"/Versand_19_DRG_PatKreis_2021.accdb\"\n",
        "\n",
        "conn = jaydebeapi.connect(\n",
        "    \"net.ucanaccess.jdbc.UcanaccessDriver\",\n",
        "    f\"jdbc:ucanaccess://{db_path}\",\n",
        "    jars=jars\n",
        ")\n",
        "cursor = conn.cursor()\n",
        "\n",
        "# Step 2: Perform efficient aggregation\n",
        "try:\n",
        "    # Create final table\n",
        "    final_table_name = \"Final_State_DRG_Analysis\"\n",
        "    cursor.execute(f\"DROP TABLE IF EXISTS `{final_table_name}`\")\n",
        "    cursor.execute(f\"\"\"\n",
        "        CREATE TABLE `{final_table_name}` (\n",
        "            state VARCHAR(255),\n",
        "            drg VARCHAR(10),\n",
        "            MDC VARCHAR(255),\n",
        "            Fachabteilung VARCHAR(255),\n",
        "            Sekundär VARCHAR(255),\n",
        "            total_patients INTEGER\n",
        "        )\n",
        "    \"\"\")\n",
        "    conn.commit()\n",
        "\n",
        "    # Get aggregated data in one query\n",
        "    print(\"Aggregating data by state and DRG...\")\n",
        "    cursor.execute(f\"\"\"\n",
        "        SELECT\n",
        "            LEFT(pat_ags5, 2) AS state_code,\n",
        "            drg,\n",
        "            SUM(patient) AS total_patients\n",
        "        FROM Versand_19_DRG_PatKreis_2021\n",
        "        GROUP BY LEFT(pat_ags5, 2), drg\n",
        "    \"\"\")\n",
        "    aggregated_data = cursor.fetchall()\n",
        "    print(f\"Aggregated into {len(aggregated_data):,} state/DRG combinations\")\n",
        "\n",
        "    # Step 3: Load DRG mapping\n",
        "    print(\"Loading DRG mapping...\")\n",
        "    mapping_df = pd.read_excel('/DRG_Fachabteilung Cluster.xlsx',\n",
        "                               sheet_name='Sheet1',\n",
        "                               skiprows=1)\n",
        "\n",
        "    mapping_dict = {}\n",
        "    for _, row in mapping_df.iterrows():\n",
        "        range_str = str(row.iloc[1])\n",
        "        if range_str == 'nan' or not range_str.strip():\n",
        "            continue\n",
        "\n",
        "        for sub_range in range_str.split(';'):\n",
        "            sub_range = sub_range.strip()\n",
        "            if '–' in sub_range:\n",
        "                parts = sub_range.split('–')\n",
        "                if len(parts) == 2:\n",
        "                    start, end = [s.strip() for s in parts]\n",
        "\n",
        "                    # Handle numeric ranges\n",
        "                    if start[0].isdigit():\n",
        "                        start_num = int(start[:3])\n",
        "                        end_num = int(end[:3])\n",
        "                        for num in range(start_num, end_num + 1):\n",
        "                            base = str(num).zfill(3)\n",
        "                            mapping_dict[base] = (\n",
        "                                str(row.iloc[0]),\n",
        "                                str(row.iloc[3]),\n",
        "                                str(row.iloc[4])\n",
        "                            )\n",
        "\n",
        "                    # Handle alpha ranges\n",
        "                    elif start[0].isalpha():\n",
        "                        current = start[:3]\n",
        "                        while current <= end[:3]:\n",
        "                            mapping_dict[current] = (\n",
        "                                str(row.iloc[0]),\n",
        "                                str(row.iloc[3]),\n",
        "                                str(row.iloc[4])\n",
        "                            )\n",
        "                            # Increment code (A01 -> A02)\n",
        "                            prefix = current[0]\n",
        "                            num = int(current[1:3]) + 1\n",
        "                            current = f\"{prefix}{num:02d}\"\n",
        "\n",
        "    print(f\"Created DRG mapping with {len(mapping_dict)} entries\")\n",
        "\n",
        "    # Step 4: Insert into final table\n",
        "    print(\"Creating final table...\")\n",
        "    insert_sql = f\"\"\"\n",
        "        INSERT INTO `{final_table_name}`\n",
        "        (state, drg, MDC, Fachabteilung, Sekundär, total_patients)\n",
        "        VALUES (?, ?, ?, ?, ?, ?)\n",
        "    \"\"\"\n",
        "\n",
        "    for state_code, drg, patients in tqdm(aggregated_data, desc=\"Processing\"):\n",
        "        state_name = state_mapping.get(str(state_code), \"Unknown\")\n",
        "        clean_drg = str(drg).strip().upper()[:3]  # Use first 3 characters\n",
        "\n",
        "        mapping = mapping_dict.get(clean_drg, (\"Unknown\", \"Unknown\", \"Unknown\"))\n",
        "\n",
        "        cursor.execute(insert_sql, (\n",
        "            state_name,\n",
        "            drg,\n",
        "            mapping[0][:254],\n",
        "            mapping[1][:254],\n",
        "            mapping[2][:254],\n",
        "            patients\n",
        "        ))\n",
        "\n",
        "    conn.commit()\n",
        "    print(f\"Created final table with {len(aggregated_data):,} rows\")\n",
        "\n",
        "    # Step 5: Verify results\n",
        "    cursor.execute(f\"SELECT COUNT(*) FROM `{final_table_name}`\")\n",
        "    final_count = cursor.fetchone()[0]\n",
        "    print(f\"Final table contains {final_count:,} rows\")\n",
        "\n",
        "    cursor.execute(f\"SELECT * FROM `{final_table_name}` LIMIT 10\")\n",
        "    print(\"\\nSample records:\")\n",
        "    for row in cursor.fetchall():\n",
        "        print(row)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "    conn.rollback()\n",
        "\n",
        "finally:\n",
        "    cursor.close()\n",
        "    conn.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Q_KLw3fVZl9",
        "outputId": "8596b466-7f6d-407e-95df-1476000aa945"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Aggregating data by state and DRG...\n",
            "Aggregated into 22,052 state/DRG combinations\n",
            "Loading DRG mapping...\n",
            "Created DRG mapping with 1942 entries\n",
            "Creating final table...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing: 100%|██████████| 22052/22052 [01:30<00:00, 244.90it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Created final table with 22,052 rows\n",
            "Final table contains 22,052 rows\n",
            "\n",
            "Sample records:\n",
            "('Schleswig-Holstein', '801A', '24 – Sonstige DRGs', 'Diverse Fachabteilungen', 'Fachabteilungen', 24)\n",
            "('Schleswig-Holstein', '801B', '24 – Sonstige DRGs', 'Diverse Fachabteilungen', 'Fachabteilungen', 126)\n",
            "('Schleswig-Holstein', '801C', '24 – Sonstige DRGs', 'Diverse Fachabteilungen', 'Fachabteilungen', 98)\n",
            "('Schleswig-Holstein', '801D', '24 – Sonstige DRGs', 'Diverse Fachabteilungen', 'Fachabteilungen', 383)\n",
            "('Schleswig-Holstein', '801E', '24 – Sonstige DRGs', 'Diverse Fachabteilungen', 'Fachabteilungen', 191)\n",
            "('Schleswig-Holstein', '802A', '24 – Sonstige DRGs', 'Diverse Fachabteilungen', 'Fachabteilungen', 61)\n",
            "('Schleswig-Holstein', '802C', '24 – Sonstige DRGs', 'Diverse Fachabteilungen', 'Fachabteilungen', 102)\n",
            "('Schleswig-Holstein', '802D', '24 – Sonstige DRGs', 'Diverse Fachabteilungen', 'Fachabteilungen', 51)\n",
            "('Schleswig-Holstein', 'A04D', 'Prä – Prä-MDC', 'Notfallaufnahme', 'Intensivmedizin', 34)\n",
            "('Schleswig-Holstein', 'A04E', 'Prä – Prä-MDC', 'Notfallaufnahme', 'Intensivmedizin', 102)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import jaydebeapi\n",
        "import glob\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "# State mapping dictionary\n",
        "state_mapping = {\n",
        "    '01': 'Schleswig-Holstein',\n",
        "    '02': 'Hamburg',\n",
        "    '03': 'Niedersachsen',\n",
        "    '04': 'Bremen',\n",
        "    '05': 'Nordrhein-Westfalen',\n",
        "    '06': 'Hessen',\n",
        "    '07': 'Rheinland-Pfalz',\n",
        "    '08': 'Baden-Württemberg',\n",
        "    '09': 'Bayern',\n",
        "    '10': 'Saarland',\n",
        "    '11': 'Berlin',\n",
        "    '12': 'Brandenburg',\n",
        "    '13': 'Mecklenburg-Vorpommern',\n",
        "    '14': 'Sachsen',\n",
        "    '15': 'Sachsen-Anhalt',\n",
        "    '16': 'Thüringen'\n",
        "}\n",
        "\n",
        "# Step 1: Connect to database\n",
        "jars = glob.glob(\"*.jar\")\n",
        "db_path = \"/versand_19_DRG_PatKreis_2022.accdb\"\n",
        "\n",
        "conn = jaydebeapi.connect(\n",
        "    \"net.ucanaccess.jdbc.UcanaccessDriver\",\n",
        "    f\"jdbc:ucanaccess://{db_path}\",\n",
        "    jars=jars\n",
        ")\n",
        "cursor = conn.cursor()\n",
        "\n",
        "# Step 2: Perform efficient aggregation\n",
        "try:\n",
        "    # Create final table\n",
        "    final_table_name = \"Final_State_DRG_Analysis\"\n",
        "    cursor.execute(f\"DROP TABLE IF EXISTS `{final_table_name}`\")\n",
        "    cursor.execute(f\"\"\"\n",
        "        CREATE TABLE `{final_table_name}` (\n",
        "            state VARCHAR(255),\n",
        "            drg VARCHAR(10),\n",
        "            MDC VARCHAR(255),\n",
        "            Fachabteilung VARCHAR(255),\n",
        "            Sekundär VARCHAR(255),\n",
        "            total_patients INTEGER\n",
        "        )\n",
        "    \"\"\")\n",
        "    conn.commit()\n",
        "\n",
        "    # Get aggregated data in one query\n",
        "    print(\"Aggregating data by state and DRG...\")\n",
        "    cursor.execute(f\"\"\"\n",
        "        SELECT\n",
        "            LEFT(pat_ags5, 2) AS state_code,\n",
        "            drg,\n",
        "            SUM(patient) AS total_patients\n",
        "        FROM Versand_19_DRG_PatKreis_2022\n",
        "        GROUP BY LEFT(pat_ags5, 2), drg\n",
        "    \"\"\")\n",
        "    aggregated_data = cursor.fetchall()\n",
        "    print(f\"Aggregated into {len(aggregated_data):,} state/DRG combinations\")\n",
        "\n",
        "    # Step 3: Load DRG mapping\n",
        "    print(\"Loading DRG mapping...\")\n",
        "    mapping_df = pd.read_excel('/DRG_Fachabteilung Cluster.xlsx',\n",
        "                               sheet_name='Sheet1',\n",
        "                               skiprows=1)\n",
        "\n",
        "    mapping_dict = {}\n",
        "    for _, row in mapping_df.iterrows():\n",
        "        range_str = str(row.iloc[1])\n",
        "        if range_str == 'nan' or not range_str.strip():\n",
        "            continue\n",
        "\n",
        "        for sub_range in range_str.split(';'):\n",
        "            sub_range = sub_range.strip()\n",
        "            if '–' in sub_range:\n",
        "                parts = sub_range.split('–')\n",
        "                if len(parts) == 2:\n",
        "                    start, end = [s.strip() for s in parts]\n",
        "\n",
        "                    # Handle numeric ranges\n",
        "                    if start[0].isdigit():\n",
        "                        start_num = int(start[:3])\n",
        "                        end_num = int(end[:3])\n",
        "                        for num in range(start_num, end_num + 1):\n",
        "                            base = str(num).zfill(3)\n",
        "                            mapping_dict[base] = (\n",
        "                                str(row.iloc[0]),\n",
        "                                str(row.iloc[3]),\n",
        "                                str(row.iloc[4])\n",
        "                            )\n",
        "\n",
        "                    # Handle alpha ranges\n",
        "                    elif start[0].isalpha():\n",
        "                        current = start[:3]\n",
        "                        while current <= end[:3]:\n",
        "                            mapping_dict[current] = (\n",
        "                                str(row.iloc[0]),\n",
        "                                str(row.iloc[3]),\n",
        "                                str(row.iloc[4])\n",
        "                            )\n",
        "                            # Increment code (A01 -> A02)\n",
        "                            prefix = current[0]\n",
        "                            num = int(current[1:3]) + 1\n",
        "                            current = f\"{prefix}{num:02d}\"\n",
        "\n",
        "    print(f\"Created DRG mapping with {len(mapping_dict)} entries\")\n",
        "\n",
        "    # Step 4: Insert into final table\n",
        "    print(\"Creating final table...\")\n",
        "    insert_sql = f\"\"\"\n",
        "        INSERT INTO `{final_table_name}`\n",
        "        (state, drg, MDC, Fachabteilung, Sekundär, total_patients)\n",
        "        VALUES (?, ?, ?, ?, ?, ?)\n",
        "    \"\"\"\n",
        "\n",
        "    for state_code, drg, patients in tqdm(aggregated_data, desc=\"Processing\"):\n",
        "        state_name = state_mapping.get(str(state_code), \"Unknown\")\n",
        "        clean_drg = str(drg).strip().upper()[:3]  # Use first 3 characters\n",
        "\n",
        "        mapping = mapping_dict.get(clean_drg, (\"Unknown\", \"Unknown\", \"Unknown\"))\n",
        "\n",
        "        cursor.execute(insert_sql, (\n",
        "            state_name,\n",
        "            drg,\n",
        "            mapping[0][:254],\n",
        "            mapping[1][:254],\n",
        "            mapping[2][:254],\n",
        "            patients\n",
        "        ))\n",
        "\n",
        "    conn.commit()\n",
        "    print(f\"Created final table with {len(aggregated_data):,} rows\")\n",
        "\n",
        "    # Step 5: Verify results\n",
        "    cursor.execute(f\"SELECT COUNT(*) FROM `{final_table_name}`\")\n",
        "    final_count = cursor.fetchone()[0]\n",
        "    print(f\"Final table contains {final_count:,} rows\")\n",
        "\n",
        "    cursor.execute(f\"SELECT * FROM `{final_table_name}` LIMIT 10\")\n",
        "    print(\"\\nSample records:\")\n",
        "    for row in cursor.fetchall():\n",
        "        print(row)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "    conn.rollback()\n",
        "\n",
        "finally:\n",
        "    cursor.close()\n",
        "    conn.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WG1qK7IUVhd",
        "outputId": "3cc035c9-864c-4422-e41f-7a91bd2df34b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Aggregating data by state and DRG...\n",
            "Aggregated into 21,915 state/DRG combinations\n",
            "Loading DRG mapping...\n",
            "Created DRG mapping with 1942 entries\n",
            "Creating final table...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing: 100%|██████████| 21915/21915 [01:23<00:00, 261.37it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Created final table with 21,915 rows\n",
            "Final table contains 21,915 rows\n",
            "\n",
            "Sample records:\n",
            "('Schleswig-Holstein', '801B', '24 – Sonstige DRGs', 'Diverse Fachabteilungen', 'Fachabteilungen', 117)\n",
            "('Schleswig-Holstein', '801D', '24 – Sonstige DRGs', 'Diverse Fachabteilungen', 'Fachabteilungen', 372)\n",
            "('Schleswig-Holstein', '801E', '24 – Sonstige DRGs', 'Diverse Fachabteilungen', 'Fachabteilungen', 184)\n",
            "('Schleswig-Holstein', '802A', '24 – Sonstige DRGs', 'Diverse Fachabteilungen', 'Fachabteilungen', 53)\n",
            "('Schleswig-Holstein', '802B', '24 – Sonstige DRGs', 'Diverse Fachabteilungen', 'Fachabteilungen', 65)\n",
            "('Schleswig-Holstein', '802C', '24 – Sonstige DRGs', 'Diverse Fachabteilungen', 'Fachabteilungen', 99)\n",
            "('Schleswig-Holstein', '802D', '24 – Sonstige DRGs', 'Diverse Fachabteilungen', 'Fachabteilungen', 52)\n",
            "('Schleswig-Holstein', 'A04E', 'Prä – Prä-MDC', 'Notfallaufnahme', 'Intensivmedizin', 87)\n",
            "('Schleswig-Holstein', 'A06C', 'Prä – Prä-MDC', 'Notfallaufnahme', 'Intensivmedizin', 7)\n",
            "('Schleswig-Holstein', 'A07B', 'Prä – Prä-MDC', 'Notfallaufnahme', 'Intensivmedizin', 41)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import jaydebeapi\n",
        "import glob\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "# State mapping dictionary\n",
        "state_mapping = {\n",
        "    '01': 'Schleswig-Holstein',\n",
        "    '02': 'Hamburg',\n",
        "    '03': 'Niedersachsen',\n",
        "    '04': 'Bremen',\n",
        "    '05': 'Nordrhein-Westfalen',\n",
        "    '06': 'Hessen',\n",
        "    '07': 'Rheinland-Pfalz',\n",
        "    '08': 'Baden-Württemberg',\n",
        "    '09': 'Bayern',\n",
        "    '10': 'Saarland',\n",
        "    '11': 'Berlin',\n",
        "    '12': 'Brandenburg',\n",
        "    '13': 'Mecklenburg-Vorpommern',\n",
        "    '14': 'Sachsen',\n",
        "    '15': 'Sachsen-Anhalt',\n",
        "    '16': 'Thüringen'\n",
        "}\n",
        "\n",
        "# Step 1: Connect to database\n",
        "jars = glob.glob(\"*.jar\")\n",
        "db_path = \"/versand_19_DRG_PatKreis_2023.accdb\"\n",
        "\n",
        "conn = jaydebeapi.connect(\n",
        "    \"net.ucanaccess.jdbc.UcanaccessDriver\",\n",
        "    f\"jdbc:ucanaccess://{db_path}\",\n",
        "    jars=jars\n",
        ")\n",
        "cursor = conn.cursor()\n",
        "\n",
        "# Step 2: Perform efficient aggregation\n",
        "try:\n",
        "    # Create final table\n",
        "    final_table_name = \"Final_State_DRG_Analysis\"\n",
        "    cursor.execute(f\"DROP TABLE IF EXISTS `{final_table_name}`\")\n",
        "    cursor.execute(f\"\"\"\n",
        "        CREATE TABLE `{final_table_name}` (\n",
        "            state VARCHAR(255),\n",
        "            drg VARCHAR(10),\n",
        "            MDC VARCHAR(255),\n",
        "            Fachabteilung VARCHAR(255),\n",
        "            Sekundär VARCHAR(255),\n",
        "            total_patients INTEGER\n",
        "        )\n",
        "    \"\"\")\n",
        "    conn.commit()\n",
        "\n",
        "    # Get aggregated data in one query\n",
        "    print(\"Aggregating data by state and DRG...\")\n",
        "    cursor.execute(f\"\"\"\n",
        "        SELECT\n",
        "            LEFT(pat_ags5, 2) AS state_code,\n",
        "            drg,\n",
        "            SUM(patient) AS total_patients\n",
        "        FROM Versand_19_DRG_PatKreis_2023\n",
        "        GROUP BY LEFT(pat_ags5, 2), drg\n",
        "    \"\"\")\n",
        "    aggregated_data = cursor.fetchall()\n",
        "    print(f\"Aggregated into {len(aggregated_data):,} state/DRG combinations\")\n",
        "\n",
        "    # Step 3: Load DRG mapping\n",
        "    print(\"Loading DRG mapping...\")\n",
        "    mapping_df = pd.read_excel('/DRG_Fachabteilung Cluster.xlsx',\n",
        "                               sheet_name='Sheet1',\n",
        "                               skiprows=1)\n",
        "\n",
        "    mapping_dict = {}\n",
        "    for _, row in mapping_df.iterrows():\n",
        "        range_str = str(row.iloc[1])\n",
        "        if range_str == 'nan' or not range_str.strip():\n",
        "            continue\n",
        "\n",
        "        for sub_range in range_str.split(';'):\n",
        "            sub_range = sub_range.strip()\n",
        "            if '–' in sub_range:\n",
        "                parts = sub_range.split('–')\n",
        "                if len(parts) == 2:\n",
        "                    start, end = [s.strip() for s in parts]\n",
        "\n",
        "                    # Handle numeric ranges\n",
        "                    if start[0].isdigit():\n",
        "                        start_num = int(start[:3])\n",
        "                        end_num = int(end[:3])\n",
        "                        for num in range(start_num, end_num + 1):\n",
        "                            base = str(num).zfill(3)\n",
        "                            mapping_dict[base] = (\n",
        "                                str(row.iloc[0]),\n",
        "                                str(row.iloc[3]),\n",
        "                                str(row.iloc[4])\n",
        "                            )\n",
        "\n",
        "                    # Handle alpha ranges\n",
        "                    elif start[0].isalpha():\n",
        "                        current = start[:3]\n",
        "                        while current <= end[:3]:\n",
        "                            mapping_dict[current] = (\n",
        "                                str(row.iloc[0]),\n",
        "                                str(row.iloc[3]),\n",
        "                                str(row.iloc[4])\n",
        "                            )\n",
        "                            # Increment code (A01 -> A02)\n",
        "                            prefix = current[0]\n",
        "                            num = int(current[1:3]) + 1\n",
        "                            current = f\"{prefix}{num:02d}\"\n",
        "\n",
        "    print(f\"Created DRG mapping with {len(mapping_dict)} entries\")\n",
        "\n",
        "    # Step 4: Insert into final table\n",
        "    print(\"Creating final table...\")\n",
        "    insert_sql = f\"\"\"\n",
        "        INSERT INTO `{final_table_name}`\n",
        "        (state, drg, MDC, Fachabteilung, Sekundär, total_patients)\n",
        "        VALUES (?, ?, ?, ?, ?, ?)\n",
        "    \"\"\"\n",
        "\n",
        "    for state_code, drg, patients in tqdm(aggregated_data, desc=\"Processing\"):\n",
        "        state_name = state_mapping.get(str(state_code), \"Unknown\")\n",
        "        clean_drg = str(drg).strip().upper()[:3]  # Use first 3 characters\n",
        "\n",
        "        mapping = mapping_dict.get(clean_drg, (\"Unknown\", \"Unknown\", \"Unknown\"))\n",
        "\n",
        "        cursor.execute(insert_sql, (\n",
        "            state_name,\n",
        "            drg,\n",
        "            mapping[0][:254],\n",
        "            mapping[1][:254],\n",
        "            mapping[2][:254],\n",
        "            patients\n",
        "        ))\n",
        "\n",
        "    conn.commit()\n",
        "    print(f\"Created final table with {len(aggregated_data):,} rows\")\n",
        "\n",
        "    # Step 5: Verify results\n",
        "    cursor.execute(f\"SELECT COUNT(*) FROM `{final_table_name}`\")\n",
        "    final_count = cursor.fetchone()[0]\n",
        "    print(f\"Final table contains {final_count:,} rows\")\n",
        "\n",
        "    cursor.execute(f\"SELECT * FROM `{final_table_name}` LIMIT 10\")\n",
        "    print(\"\\nSample records:\")\n",
        "    for row in cursor.fetchall():\n",
        "        print(row)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "    conn.rollback()\n",
        "\n",
        "finally:\n",
        "    cursor.close()\n",
        "    conn.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElrnurakbszZ",
        "outputId": "8d8a0ff8-68b5-4e93-ba01-7d42b9d7a50a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Processing database: /Versand_19_DRG_PatKreis_2021.accdb\n",
            "Aggregating data by state, MDC, Fachabteilung and Sekundär...\n",
            "Created table with 488 aggregated records\n",
            "\n",
            "Sample records:\n",
            "('Schleswig-Holstein', '24 – Sonstige DRGs', 'Diverse Fachabteilungen', 'Fachabteilungen', 1117)\n",
            "('Schleswig-Holstein', '-1 – Fehler-DRGs und sonstige DRGs', 'nan', 'nan', 18)\n",
            "('Schleswig-Holstein', 'Prä – Prä-MDC', 'Notfallaufnahme', 'Intensivmedizin', 4830)\n",
            "('Schleswig-Holstein', '01 – Krankheiten und Störungen des Nervensystems', 'Neurologi', 'Neurochirurgie', 48182)\n",
            "('Schleswig-Holstein', '02 – Krankheiten und Störungen des Auges', 'Augenheilkunde (Ophthalmologie)', 'nan', 13867)\n",
            "\n",
            "Processing database: /versand_19_DRG_PatKreis_2022.accdb\n",
            "Aggregating data by state, MDC, Fachabteilung and Sekundär...\n",
            "Created table with 483 aggregated records\n",
            "\n",
            "Sample records:\n",
            "('Schleswig-Holstein', '24 – Sonstige DRGs', 'Diverse Fachabteilungen', 'Fachabteilungen', 1089)\n",
            "('Schleswig-Holstein', 'Prä – Prä-MDC', 'Notfallaufnahme', 'Intensivmedizin', 4599)\n",
            "('Schleswig-Holstein', '01 – Krankheiten und Störungen des Nervensystems', 'Neurologi', 'Neurochirurgie', 45724)\n",
            "('Schleswig-Holstein', '02 – Krankheiten und Störungen des Auges', 'Augenheilkunde (Ophthalmologie)', 'nan', 13826)\n",
            "('Schleswig-Holstein', '03 –\\xa0Krankheiten und Störungen des Ohres, des Mundes und des Halses', 'HNO (Hals-Nasen-Ohren)', 'nan', 22681)\n",
            "\n",
            "Processing database: /versand_19_DRG_PatKreis_2023.accdb\n",
            "Aggregating data by state, MDC, Fachabteilung and Sekundär...\n",
            "Created table with 487 aggregated records\n",
            "\n",
            "Sample records:\n",
            "('Schleswig-Holstein', '24 – Sonstige DRGs', 'Diverse Fachabteilungen', 'Fachabteilungen', 1046)\n",
            "('Schleswig-Holstein', 'Prä – Prä-MDC', 'Notfallaufnahme', 'Intensivmedizin', 4599)\n",
            "('Schleswig-Holstein', '01 – Krankheiten und Störungen des Nervensystems', 'Neurologi', 'Neurochirurgie', 47532)\n",
            "('Schleswig-Holstein', '02 – Krankheiten und Störungen des Auges', 'Augenheilkunde (Ophthalmologie)', 'nan', 14418)\n",
            "('Schleswig-Holstein', '03 –\\xa0Krankheiten und Störungen des Ohres, des Mundes und des Halses', 'HNO (Hals-Nasen-Ohren)', 'nan', 24705)\n",
            "\n",
            "Processing completed for all databases!\n"
          ]
        }
      ],
      "source": [
        "import jaydebeapi\n",
        "import glob\n",
        "\n",
        "# Files to process\n",
        "db_files = [\n",
        "    \"/Versand_19_DRG_PatKreis_2021.accdb\",\n",
        "    \"/versand_19_DRG_PatKreis_2022.accdb\",\n",
        "    \"/versand_19_DRG_PatKreis_2023.accdb\"\n",
        "]\n",
        "\n",
        "jars = glob.glob(\"*.jar\")\n",
        "\n",
        "for db_path in db_files:\n",
        "    print(f\"\\nProcessing database: {db_path}\")\n",
        "\n",
        "    # Connect to database\n",
        "    conn = jaydebeapi.connect(\n",
        "        \"net.ucanaccess.jdbc.UcanaccessDriver\",\n",
        "        f\"jdbc:ucanaccess://{db_path}\",\n",
        "        jars=jars\n",
        "    )\n",
        "    cursor = conn.cursor()\n",
        "\n",
        "    try:\n",
        "        # Step 1: Create new aggregated table with LONG data type\n",
        "        new_table_name = \"State_MDC_Aggregation\"\n",
        "        cursor.execute(f\"DROP TABLE IF EXISTS `{new_table_name}`\")\n",
        "        cursor.execute(f\"\"\"\n",
        "            CREATE TABLE `{new_table_name}` (\n",
        "                state VARCHAR(255),\n",
        "                MDC VARCHAR(255),\n",
        "                Fachabteilung VARCHAR(255),\n",
        "                Sekundär VARCHAR(255),\n",
        "                total_patients LONG  -- Changed to LONG to support larger numbers\n",
        "            )\n",
        "        \"\"\")\n",
        "        conn.commit()\n",
        "\n",
        "        # Step 2: Populate new table with aggregated data\n",
        "        print(\"Aggregating data by state, MDC, Fachabteilung and Sekundär...\")\n",
        "        cursor.execute(f\"\"\"\n",
        "            INSERT INTO `{new_table_name}`\n",
        "            (state, MDC, Fachabteilung, Sekundär, total_patients)\n",
        "            SELECT\n",
        "                state,\n",
        "                MDC,\n",
        "                Fachabteilung,\n",
        "                Sekundär,\n",
        "                SUM(CLng(total_patients)) AS total_patients  -- Cast to LONG before summing\n",
        "            FROM Final_State_DRG_Analysis\n",
        "            GROUP BY state, MDC, Fachabteilung, Sekundär\n",
        "        \"\"\")\n",
        "        conn.commit()\n",
        "\n",
        "        # Step 3: Verify results\n",
        "        cursor.execute(f\"SELECT COUNT(*) FROM `{new_table_name}`\")\n",
        "        row_count = cursor.fetchone()[0]\n",
        "        print(f\"Created table with {row_count} aggregated records\")\n",
        "\n",
        "        cursor.execute(f\"SELECT * FROM `{new_table_name}` LIMIT 5\")\n",
        "        print(\"\\nSample records:\")\n",
        "        for row in cursor.fetchall():\n",
        "            print(row)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        conn.rollback()\n",
        "\n",
        "    finally:\n",
        "        cursor.close()\n",
        "        conn.close()\n",
        "\n",
        "print(\"\\nProcessing completed for all databases!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u9lX2auLbs2Z"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v3wqKZIDg4u0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dS6fnV3Xg4xk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cpuyzmzSg40J",
        "outputId": "63ec3fbe-603d-4691-f1aa-049d6cfb4e90"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
            "  warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "Schema for KHV_2021 Sheet:\n",
            "==================================================\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2769 entries, 0 to 2768\n",
            "Columns: 170 entries, Land to 3758\n",
            "dtypes: float64(151), int64(9), object(10)\n",
            "memory usage: 3.6+ MB\n",
            "\n",
            "First 5 rows of KHV_2021:\n",
            "   Land  Kreis  Gemeinde                                       Adresse_Name  \\\n",
            "0     1    1.0       0.0                            DIAKO Krankenhaus gGmbH   \n",
            "1     1    1.0       0.0  DIAKO Nordfriesland gGmbH - DIAKO Fachklinik f...   \n",
            "2     1    1.0       0.0  DIAKO Nordfriesland gGmbH - DIAKO Tagesklinike...   \n",
            "3     1    1.0       0.0  DIAKO Nordfriesland gGmbH - DIAKO Tagesklinike...   \n",
            "4     1    1.0       0.0  DIAKO Nordfriesland gGmbH - DIAKO Tagesklinike...   \n",
            "\n",
            "                               Adresse_Name_Standort Adresse_Strasse_Standort  \\\n",
            "0                            DIAKO Krankenhaus gGmbH              Knuthstraße   \n",
            "1  DIAKO Fachklinik für Psychiatrie, Psychosomati...              Knuthstraße   \n",
            "2             DIAKO Tagesklinik für Ältere Flensburg        Marienhölzungsweg   \n",
            "3         DIAKO Tagesklinik für Erwachsene Flensburg        Marienhölzungsweg   \n",
            "4          DIAKO Tagesklinik für KJP (Villa Paletti)        Marienhölzungsweg   \n",
            "\n",
            "  Adresse_Haus-Nr._Standort  Adresse_Postleitzahl_Standort  \\\n",
            "0                         1                        24939.0   \n",
            "1                         1                        24939.0   \n",
            "2                         8                        24939.0   \n",
            "3                        21                        24939.0   \n",
            "4                        68                        24939.0   \n",
            "\n",
            "  Adresse_Ort_Standort Telefonvorwahl/-nummer  ... 3700 3750  3751 3752  3753  \\\n",
            "0            Flensburg          0461 812-2026  ...  NaN  NaN   NaN  NaN   NaN   \n",
            "1            Flensburg         04671 408114-0  ...  NaN  NaN   NaN  NaN   NaN   \n",
            "2            Flensburg                    NaN  ...  NaN  NaN   NaN  NaN   NaN   \n",
            "3            Flensburg                    NaN  ...  NaN  NaN   NaN  NaN   NaN   \n",
            "4            Flensburg                    NaN  ...  NaN  NaN   NaN  NaN   NaN   \n",
            "\n",
            "   3754  3755  3756  3757  3758  \n",
            "0   NaN   NaN   NaN   NaN   NaN  \n",
            "1   NaN   NaN   NaN   NaN   NaN  \n",
            "2   NaN   NaN   NaN   NaN   NaN  \n",
            "3   NaN   NaN   NaN   NaN   NaN  \n",
            "4   NaN   NaN   NaN   NaN   NaN  \n",
            "\n",
            "[5 rows x 170 columns]\n",
            "\n",
            "==================================================\n",
            "Schema for RHV_2021 Sheet:\n",
            "==================================================\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1092 entries, 0 to 1091\n",
            "Data columns (total 58 columns):\n",
            " #   Column                  Non-Null Count  Dtype  \n",
            "---  ------                  --------------  -----  \n",
            " 0   Land                    1092 non-null   int64  \n",
            " 1   Kreis                   1092 non-null   int64  \n",
            " 2   Gemeinde                1092 non-null   int64  \n",
            " 3   Adresse_Name            1092 non-null   object \n",
            " 4   Adresse_Straße          1090 non-null   object \n",
            " 5   Adresse_Haus-Nr.        1063 non-null   object \n",
            " 6   Adresse_Postleitzahl    1092 non-null   int64  \n",
            " 7   Adresse_Ort             1092 non-null   object \n",
            " 8   Telefonvorwahl/-nummer  1043 non-null   object \n",
            " 9   E-Mail Adresse          1033 non-null   object \n",
            " 10  Internet-Adresse        1040 non-null   object \n",
            " 11  Traeger                 1092 non-null   int64  \n",
            " 12  T-Name                  1092 non-null   object \n",
            " 13  EinrichtungsTyp         1092 non-null   int64  \n",
            " 14  INSG                    1092 non-null   int64  \n",
            " 15  0000                    90 non-null     float64\n",
            " 16  0100                    91 non-null     float64\n",
            " 17  0200                    153 non-null    float64\n",
            " 18  0300                    103 non-null    float64\n",
            " 19  0400                    3 non-null      float64\n",
            " 20  0500                    70 non-null     float64\n",
            " 21  0600                    7 non-null      float64\n",
            " 22  0700                    17 non-null     float64\n",
            " 23  0800                    29 non-null     float64\n",
            " 24  0900                    18 non-null     float64\n",
            " 25  1000                    34 non-null     float64\n",
            " 26  1100                    0 non-null      float64\n",
            " 27  1200                    0 non-null      float64\n",
            " 28  1300                    0 non-null      float64\n",
            " 29  1400                    22 non-null     float64\n",
            " 30  1500                    5 non-null      float64\n",
            " 31  1600                    1 non-null      float64\n",
            " 32  1700                    0 non-null      float64\n",
            " 33  1800                    1 non-null      float64\n",
            " 34  1900                    0 non-null      float64\n",
            " 35  2000                    0 non-null      float64\n",
            " 36  2100                    1 non-null      float64\n",
            " 37  2200                    10 non-null     float64\n",
            " 38  2300                    354 non-null    float64\n",
            " 39  2400                    10 non-null     float64\n",
            " 40  2500                    0 non-null      float64\n",
            " 41  2600                    11 non-null     float64\n",
            " 42  2700                    2 non-null      float64\n",
            " 43  2800                    163 non-null    float64\n",
            " 44  2900                    14 non-null     float64\n",
            " 45  3000                    2 non-null      float64\n",
            " 46  3100                    198 non-null    float64\n",
            " 47  3200                    0 non-null      float64\n",
            " 48  3300                    0 non-null      float64\n",
            " 49  3400                    19 non-null     float64\n",
            " 50  3500                    0 non-null      float64\n",
            " 51  3600                    0 non-null      float64\n",
            " 52  3700                    79 non-null     float64\n",
            " 53  8200                    24 non-null     float64\n",
            " 54  8500                    130 non-null    float64\n",
            " 55  8600                    9 non-null      float64\n",
            " 56  8800                    30 non-null     float64\n",
            " 57  9000                    5 non-null      float64\n",
            "dtypes: float64(43), int64(7), object(8)\n",
            "memory usage: 494.9+ KB\n",
            "\n",
            "First 5 rows of RHV_2021:\n",
            "   Land  Kreis  Gemeinde                          Adresse_Name  \\\n",
            "0     1      3         0            AMEOS Reha Klinikum Lübeck   \n",
            "1     1      3         0  Fachklinik für Rehabilitation DO IT!   \n",
            "2     1     51        13          AWO-Nordseeklinik Erlengrund   \n",
            "3     1     51        13        Ev. Kurzentrum GODE TIED Büsum   \n",
            "4     1     51        34                   Klinik Nordseedeich   \n",
            "\n",
            "             Adresse_Straße Adresse_Haus-Nr.  Adresse_Postleitzahl  \\\n",
            "0                 Weidenweg             9-15                 23562   \n",
            "1  Mecklenburger Landstraße               60                 23570   \n",
            "2             Nordseestraße              100                 25761   \n",
            "3       Königsberger Straße            12-16                 25761   \n",
            "4                  Deichweg                1                 25718   \n",
            "\n",
            "      Adresse_Ort Telefonvorwahl/-nummer  \\\n",
            "0          Lübeck                    NaN   \n",
            "1          Lübeck        040 200010-7086   \n",
            "2           Büsum          0231 5483-249   \n",
            "3           Büsum         04834 950-9130   \n",
            "4  Friedrichskoog          04854 908-400   \n",
            "\n",
            "                          E-Mail Adresse  ... 3300  3400 3500  3600  3700  \\\n",
            "0            lgah.verw@neustadt.ameos.de  ...  NaN   NaN  NaN   NaN   NaN   \n",
            "1          Katrin-Grenz@therapiehilfe.de  ...  NaN   NaN  NaN   NaN  70.0   \n",
            "2              joerg.langemann@aw-kur.de  ...  NaN   NaN  NaN   NaN   NaN   \n",
            "3  Katrin.Schmidt@godetied.nordkirche.de  ...  NaN   NaN  NaN   NaN   NaN   \n",
            "4          siegel@klinik-nordseedeich.de  ...  NaN   NaN  NaN   NaN   NaN   \n",
            "\n",
            "   8200  8500  8600  8800  9000  \n",
            "0   NaN  86.0   NaN   NaN   NaN  \n",
            "1   NaN   NaN   NaN   NaN   NaN  \n",
            "2   NaN   NaN   NaN   NaN   NaN  \n",
            "3  40.0   NaN   NaN   NaN   NaN  \n",
            "4   NaN   NaN   NaN   NaN   NaN  \n",
            "\n",
            "[5 rows x 58 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from google.colab import files\n",
        "\n",
        "file_name = \"/Krankenhausverzeichnis_2021.xlsx\"\n",
        "\n",
        "# Read sheets skipping first 4 empty rows\n",
        "khv_df = pd.read_excel(file_name, sheet_name=\"KHV_2021\", skiprows=4)\n",
        "rhv_df = pd.read_excel(file_name, sheet_name=\"RHV_2021\", skiprows=4)\n",
        "\n",
        "# Print schema for KHV_2021\n",
        "print(\"=\"*50)\n",
        "print(\"Schema for KHV_2021 Sheet:\")\n",
        "print(\"=\"*50)\n",
        "khv_df.info()\n",
        "\n",
        "# Print first 5 rows of KHV_2021\n",
        "print(\"\\nFirst 5 rows of KHV_2021:\")\n",
        "print(khv_df.head())\n",
        "\n",
        "# Print schema for RHV_2021\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Schema for RHV_2021 Sheet:\")\n",
        "print(\"=\"*50)\n",
        "rhv_df.info()\n",
        "\n",
        "# Print first 5 rows of RHV_2021\n",
        "print(\"\\nFirst 5 rows of RHV_2021:\")\n",
        "print(rhv_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8UVNgny40LF",
        "outputId": "4c34fe7a-5c1c-4375-8a13-2392fb79704a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "Processed KHV_2021 DataFrame:\n",
            "==================================================\n",
            "Land column used: Land\n",
            "                 Land  Kreis  Gemeinde  \\\n",
            "0  Schleswig-Holstein    1.0       0.0   \n",
            "1  Schleswig-Holstein    1.0       0.0   \n",
            "2  Schleswig-Holstein    1.0       0.0   \n",
            "3  Schleswig-Holstein    1.0       0.0   \n",
            "4  Schleswig-Holstein    1.0       0.0   \n",
            "\n",
            "                                        Adresse_Name  \\\n",
            "0                            DIAKO Krankenhaus gGmbH   \n",
            "1  DIAKO Nordfriesland gGmbH - DIAKO Fachklinik f...   \n",
            "2  DIAKO Nordfriesland gGmbH - DIAKO Tagesklinike...   \n",
            "3  DIAKO Nordfriesland gGmbH - DIAKO Tagesklinike...   \n",
            "4  DIAKO Nordfriesland gGmbH - DIAKO Tagesklinike...   \n",
            "\n",
            "                               Adresse_Name_Standort Adresse_Strasse_Standort  \\\n",
            "0                            DIAKO Krankenhaus gGmbH              Knuthstraße   \n",
            "1  DIAKO Fachklinik für Psychiatrie, Psychosomati...              Knuthstraße   \n",
            "2             DIAKO Tagesklinik für Ältere Flensburg        Marienhölzungsweg   \n",
            "3         DIAKO Tagesklinik für Erwachsene Flensburg        Marienhölzungsweg   \n",
            "4          DIAKO Tagesklinik für KJP (Villa Paletti)        Marienhölzungsweg   \n",
            "\n",
            "  Adresse_Haus-Nr._Standort  Adresse_Postleitzahl_Standort  \\\n",
            "0                         1                        24939.0   \n",
            "1                         1                        24939.0   \n",
            "2                         8                        24939.0   \n",
            "3                        21                        24939.0   \n",
            "4                        68                        24939.0   \n",
            "\n",
            "  Adresse_Ort_Standort Telefonvorwahl/-nummer  ... 3700 3750  3751 3752  3753  \\\n",
            "0            Flensburg          0461 812-2026  ...  NaN  NaN   NaN  NaN   NaN   \n",
            "1            Flensburg         04671 408114-0  ...  NaN  NaN   NaN  NaN   NaN   \n",
            "2            Flensburg                    NaN  ...  NaN  NaN   NaN  NaN   NaN   \n",
            "3            Flensburg                    NaN  ...  NaN  NaN   NaN  NaN   NaN   \n",
            "4            Flensburg                    NaN  ...  NaN  NaN   NaN  NaN   NaN   \n",
            "\n",
            "   3754  3755  3756  3757  3758  \n",
            "0   NaN   NaN   NaN   NaN   NaN  \n",
            "1   NaN   NaN   NaN   NaN   NaN  \n",
            "2   NaN   NaN   NaN   NaN   NaN  \n",
            "3   NaN   NaN   NaN   NaN   NaN  \n",
            "4   NaN   NaN   NaN   NaN   NaN  \n",
            "\n",
            "[5 rows x 170 columns]\n",
            "\n",
            "==================================================\n",
            "Processed RHV_2021 DataFrame:\n",
            "==================================================\n",
            "Land column used: Land\n",
            "                 Land  Kreis  Gemeinde                          Adresse_Name  \\\n",
            "0  Schleswig-Holstein      3         0            AMEOS Reha Klinikum Lübeck   \n",
            "1  Schleswig-Holstein      3         0  Fachklinik für Rehabilitation DO IT!   \n",
            "2  Schleswig-Holstein     51        13          AWO-Nordseeklinik Erlengrund   \n",
            "3  Schleswig-Holstein     51        13        Ev. Kurzentrum GODE TIED Büsum   \n",
            "4  Schleswig-Holstein     51        34                   Klinik Nordseedeich   \n",
            "\n",
            "             Adresse_Straße Adresse_Haus-Nr.  Adresse_Postleitzahl  \\\n",
            "0                 Weidenweg             9-15                 23562   \n",
            "1  Mecklenburger Landstraße               60                 23570   \n",
            "2             Nordseestraße              100                 25761   \n",
            "3       Königsberger Straße            12-16                 25761   \n",
            "4                  Deichweg                1                 25718   \n",
            "\n",
            "      Adresse_Ort Telefonvorwahl/-nummer  \\\n",
            "0          Lübeck                    NaN   \n",
            "1          Lübeck        040 200010-7086   \n",
            "2           Büsum          0231 5483-249   \n",
            "3           Büsum         04834 950-9130   \n",
            "4  Friedrichskoog          04854 908-400   \n",
            "\n",
            "                          E-Mail Adresse  ... 3300  3400 3500  3600  3700  \\\n",
            "0            lgah.verw@neustadt.ameos.de  ...  NaN   NaN  NaN   NaN   NaN   \n",
            "1          Katrin-Grenz@therapiehilfe.de  ...  NaN   NaN  NaN   NaN  70.0   \n",
            "2              joerg.langemann@aw-kur.de  ...  NaN   NaN  NaN   NaN   NaN   \n",
            "3  Katrin.Schmidt@godetied.nordkirche.de  ...  NaN   NaN  NaN   NaN   NaN   \n",
            "4          siegel@klinik-nordseedeich.de  ...  NaN   NaN  NaN   NaN   NaN   \n",
            "\n",
            "   8200  8500  8600  8800  9000  \n",
            "0   NaN  86.0   NaN   NaN   NaN  \n",
            "1   NaN   NaN   NaN   NaN   NaN  \n",
            "2   NaN   NaN   NaN   NaN   NaN  \n",
            "3  40.0   NaN   NaN   NaN   NaN  \n",
            "4   NaN   NaN   NaN   NaN   NaN  \n",
            "\n",
            "[5 rows x 58 columns]\n"
          ]
        }
      ],
      "source": [
        "# Define state mapping dictionary\n",
        "state_mapping = {\n",
        "    '01': 'Schleswig-Holstein',\n",
        "    '02': 'Hamburg',\n",
        "    '03': 'Niedersachsen',\n",
        "    '04': 'Bremen',\n",
        "    '05': 'Nordrhein-Westfalen',\n",
        "    '06': 'Hessen',\n",
        "    '07': 'Rheinland-Pfalz',\n",
        "    '08': 'Baden-Württemberg',\n",
        "    '09': 'Bayern',\n",
        "    '10': 'Saarland',\n",
        "    '11': 'Berlin',\n",
        "    '12': 'Brandenburg',\n",
        "    '13': 'Mecklenburg-Vorpommern',\n",
        "    '14': 'Sachsen',\n",
        "    '15': 'Sachsen-Anhalt',\n",
        "    '16': 'Thüringen'\n",
        "}\n",
        "\n",
        "def replace_land_codes(df):\n",
        "    \"\"\"Replace numerical land codes with state names in DataFrame\"\"\"\n",
        "    # Find the land column (case-insensitive search)\n",
        "    land_col = None\n",
        "    for col in df.columns:\n",
        "        if 'land' in col.lower():\n",
        "            land_col = col\n",
        "            break\n",
        "\n",
        "    if land_col:\n",
        "        # Convert to string and clean values\n",
        "        df[land_col] = df[land_col].astype(str).str.strip().str.zfill(2)\n",
        "        # Replace using mapping dictionary\n",
        "        df[land_col] = df[land_col].map(state_mapping)\n",
        "        return df, land_col\n",
        "    return df, None\n",
        "\n",
        "# Process KHV_2021\n",
        "khv_df, khv_land_col = replace_land_codes(khv_df)\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Processed KHV_2021 DataFrame:\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Land column used: {khv_land_col}\")\n",
        "print(khv_df.head())\n",
        "\n",
        "# Process RHV_2021\n",
        "rhv_df, rhv_land_col = replace_land_codes(rhv_df)\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Processed RHV_2021 DataFrame:\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Land column used: {rhv_land_col}\")\n",
        "print(rhv_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNgyU7h_40NP",
        "outputId": "5dcb2e69-c660-4531-c626-492b0579cad2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     Land  Kreis  Gemeinde                                       Adresse_Name  \\\n",
            "0     NaN    1.0       0.0                            DIAKO Krankenhaus gGmbH   \n",
            "1     NaN    1.0       0.0  DIAKO Nordfriesland gGmbH - DIAKO Fachklinik f...   \n",
            "2     NaN    1.0       0.0  DIAKO Nordfriesland gGmbH - DIAKO Tagesklinike...   \n",
            "3     NaN    1.0       0.0  DIAKO Nordfriesland gGmbH - DIAKO Tagesklinike...   \n",
            "4     NaN    1.0       0.0  DIAKO Nordfriesland gGmbH - DIAKO Tagesklinike...   \n",
            "...   ...    ...       ...                                                ...   \n",
            "2778  NaN   77.0       1.0  Ev. Lukas-Stiftung Altenburg, Klinik für Psych...   \n",
            "2779  NaN   77.0       1.0                     Klinikum Altenburger Land GmbH   \n",
            "2780  NaN   77.0       1.0                          Universitätsklinikum Jena   \n",
            "2781  NaN    NaN       NaN                                                NaN   \n",
            "2782  NaN    NaN       NaN                                                NaN   \n",
            "\n",
            "                                  Adresse_Name_Standort  \\\n",
            "0                               DIAKO Krankenhaus gGmbH   \n",
            "1     DIAKO Fachklinik für Psychiatrie, Psychosomati...   \n",
            "2                DIAKO Tagesklinik für Ältere Flensburg   \n",
            "3            DIAKO Tagesklinik für Erwachsene Flensburg   \n",
            "4             DIAKO Tagesklinik für KJP (Villa Paletti)   \n",
            "...                                                 ...   \n",
            "2778  Evangelische Lukas-Stiftung Altenburg, Klinik ...   \n",
            "2779                          Klinikum Altenburger Land   \n",
            "2780               PIA Kinder und Jugendliche Altenburg   \n",
            "2781                                                NaN   \n",
            "2782                                                NaN   \n",
            "\n",
            "       Adresse_Strasse_Standort Adresse_Haus-Nr._Standort  \\\n",
            "0                   Knuthstraße                         1   \n",
            "1                   Knuthstraße                         1   \n",
            "2             Marienhölzungsweg                         8   \n",
            "3             Marienhölzungsweg                        21   \n",
            "4             Marienhölzungsweg                        68   \n",
            "...                         ...                       ...   \n",
            "2778             Zeitzer Straße                        28   \n",
            "2779              Am Waldessaum                        10   \n",
            "2780  Rudolf-Breitscheid-Straße                       11a   \n",
            "2781                        NaN                       NaN   \n",
            "2782                        NaN                       NaN   \n",
            "\n",
            "      Adresse_Postleitzahl_Standort Adresse_Ort_Standort  \\\n",
            "0                           24939.0            Flensburg   \n",
            "1                           24939.0            Flensburg   \n",
            "2                           24939.0            Flensburg   \n",
            "3                           24939.0            Flensburg   \n",
            "4                           24939.0            Flensburg   \n",
            "...                             ...                  ...   \n",
            "2778                         4600.0            Altenburg   \n",
            "2779                         4600.0            Altenburg   \n",
            "2780                         4600.0            Altenburg   \n",
            "2781                            NaN                  NaN   \n",
            "2782                            NaN                  NaN   \n",
            "\n",
            "     Telefonvorwahl -nummer  ... 3750 3751  3752 3753  3754  3755  3756  3757  \\\n",
            "0                0461 812-0  ...  NaN  NaN   NaN  NaN   NaN   NaN   NaN   NaN   \n",
            "1             0461 812-1701  ...  NaN  NaN   NaN  NaN   NaN   NaN   NaN   NaN   \n",
            "2               04671 408-0  ...  NaN  NaN   NaN  NaN   NaN   NaN   NaN   NaN   \n",
            "3               04671 408-0  ...  NaN  NaN   NaN  NaN   NaN   NaN   NaN   NaN   \n",
            "4               04671 408-0  ...  NaN  NaN   NaN  NaN   NaN   NaN   NaN   NaN   \n",
            "...                     ...  ...  ...  ...   ...  ...   ...   ...   ...   ...   \n",
            "2778            03447 562-0  ...  NaN  NaN   NaN  NaN   NaN   NaN   NaN   NaN   \n",
            "2779             03447 52-0  ...  NaN  NaN   4.0  NaN   NaN   NaN   NaN   NaN   \n",
            "2780            03641 93-00  ...  NaN  NaN   NaN  NaN   NaN   NaN   NaN   NaN   \n",
            "2781                    NaN  ...  NaN  NaN   NaN  NaN   NaN   NaN   NaN   NaN   \n",
            "2782                    NaN  ...  NaN  NaN   NaN  NaN   NaN   NaN   NaN   NaN   \n",
            "\n",
            "      3758  3759  \n",
            "0      NaN   NaN  \n",
            "1      NaN   NaN  \n",
            "2      NaN   NaN  \n",
            "3      NaN   NaN  \n",
            "4      NaN   NaN  \n",
            "...    ...   ...  \n",
            "2778   NaN   NaN  \n",
            "2779   NaN   NaN  \n",
            "2780   NaN   NaN  \n",
            "2781   NaN   NaN  \n",
            "2782   NaN   NaN  \n",
            "\n",
            "[2783 rows x 172 columns]\n"
          ]
        }
      ],
      "source": [
        "file_name = \"/Krankenhausverzeichnis_2023.xlsx\"\n",
        "\n",
        "# Read sheets skipping first 4 empty rows\n",
        "khv_df = pd.read_excel(file_name, sheet_name=\" KHV_2023\", skiprows=2)\n",
        "rhv_df = pd.read_excel(file_name, sheet_name=\"RHV_2023\", skiprows=2)\n",
        "\n",
        "# print(khv_df)\n",
        "# print(rhv_df)\n",
        "\n",
        "# Define state mapping dictionary\n",
        "state_mapping = {\n",
        "    '01': 'Schleswig-Holstein',\n",
        "    '02': 'Hamburg',\n",
        "    '03': 'Niedersachsen',\n",
        "    '04': 'Bremen',\n",
        "    '05': 'Nordrhein-Westfalen',\n",
        "    '06': 'Hessen',\n",
        "    '07': 'Rheinland-Pfalz',\n",
        "    '08': 'Baden-Württemberg',\n",
        "    '09': 'Bayern',\n",
        "    '10': 'Saarland',\n",
        "    '11': 'Berlin',\n",
        "    '12': 'Brandenburg',\n",
        "    '13': 'Mecklenburg-Vorpommern',\n",
        "    '14': 'Sachsen',\n",
        "    '15': 'Sachsen-Anhalt',\n",
        "    '16': 'Thüringen'\n",
        "}\n",
        "\n",
        "# Function to replace land codes with state names\n",
        "def replace_land_codes(df):\n",
        "    land_col = None\n",
        "    for col in df.columns:\n",
        "        if 'land' in col.lower():\n",
        "            land_col = col\n",
        "            break\n",
        "\n",
        "    if land_col:\n",
        "        df[land_col] = df[land_col].astype(str).str.strip().str.zfill(2)\n",
        "        df[land_col] = df[land_col].map(state_mapping)\n",
        "        return df, land_col\n",
        "    return df, None\n",
        "\n",
        "# Process both dataframes\n",
        "khv_df, khv_land_col = replace_land_codes(khv_df)\n",
        "rhv_df, rhv_land_col = replace_land_codes(rhv_df)\n",
        "\n",
        "# Define department columns for each sheet\n",
        "# RHV departments\n",
        "rhv_departments = [\n",
        "    'INSG', '0000', '0100', '0200', '0300', '0400', '0500', '0600', '0700', '0800', '0900',\n",
        "    '1000', '1100', '1200', '1300', '1400', '1500', '1600', '1700', '1800', '1900',\n",
        "    '2000', '2100', '2200', '2300', '2400', '2500', '2600', '2700', '2800', '2900',\n",
        "    '3000', '3100', '3200', '3300', '3400', '3500', '3600', '3700',\n",
        "    '8200', '8500', '8600', '8800', '9000'\n",
        "]\n",
        "\n",
        "# KHV departments\n",
        "khv_departments = [\n",
        "    'INSG',\n",
        "    '0100', '0102', '0103', '0104', '0105', '0106', '0107', '0108', '0109', '0114',\n",
        "    '0150', '0151', '0152', '0153', '0154', '0156',\n",
        "    '0200', '0224', '0260', '0261',\n",
        "    '0300',\n",
        "    '0400', '0410', '0436',\n",
        "    '0500', '0510', '0524', '0533',\n",
        "    '0600', '0607', '0610',\n",
        "    '0700', '0706', '0710',\n",
        "    '0800',\n",
        "    '0900', '0910',\n",
        "    '1000', '1004', '1005', '1006', '1007', '1009', '1011', '1012', '1014', '1028', '1050', '1051',\n",
        "    '1100', '1136',\n",
        "    '1200',\n",
        "    '1300',\n",
        "    '1400', '1410',\n",
        "    '1500', '1513', '1516', '1518', '1519', '1520', '1523', '1536', '1550', '1551',\n",
        "    '1600',\n",
        "    '1700',\n",
        "    '1800',\n",
        "    '1900',\n",
        "    '2000', '2021', '2036', '2050',\n",
        "    '2100', '2118', '2120', '2136', '2150',\n",
        "    '2200',\n",
        "    '2300', '2309', '2315', '2316',\n",
        "    '2400', '2402', '2405', '2406', '2425',\n",
        "    '2500',\n",
        "    '2600',\n",
        "    '2700',\n",
        "    '2800', '2810', '2851', '2852', '2856',\n",
        "    '2900', '2928', '2930', '2931', '2950', '2951', '2952', '2953', '2954', '2955', '2956', '2960', '2961',\n",
        "    '3000', '3060', '3061',\n",
        "    '3100', '3110', '3160', '3161',\n",
        "    '3200', '3233',\n",
        "    '3300', '3305', '3350',\n",
        "    '3400', '3460',\n",
        "    '3500',\n",
        "    '3600', '3601', '3603', '3610', '3617', '3618', '3621', '3622', '3624', '3626', '3628', '3650', '3651', '3652',\n",
        "    '3700', '3750', '3751', '3752', '3753', '3754', '3755', '3756', '3757', '3758','3759'\n",
        "]\n",
        "\n",
        "# Convert all column names to strings for matching\n",
        "khv_df.columns = khv_df.columns.astype(str)\n",
        "rhv_df.columns = rhv_df.columns.astype(str)\n",
        "\n",
        "# Select only land column and department columns that exist in the dataframe\n",
        "def select_departments(df, land_col, departments):\n",
        "    # Find columns that actually exist in the dataframe\n",
        "    existing_cols = [col for col in departments if col in df.columns]\n",
        "    return df[[land_col] + existing_cols]\n",
        "\n",
        "\n",
        "\n",
        "# Select relevant columns\n",
        "khv_selected = select_departments(khv_df, khv_land_col, khv_departments)\n",
        "rhv_selected = select_departments(rhv_df, rhv_land_col, rhv_departments)\n",
        "\n",
        "\n",
        "print(khv_df)\n",
        "# print(rhv_df)\n",
        "\n",
        "# # Convert all department columns to numeric\n",
        "# def convert_to_numeric(df, land_col):\n",
        "#     # Identify numeric columns (all except land column)\n",
        "#     num_cols = [col for col in df.columns if col != land_col]\n",
        "\n",
        "#     # Convert to numeric, coercing errors to NaN\n",
        "#     for col in num_cols:\n",
        "#         df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "#     # Fill NaN with 0\n",
        "#     df[num_cols] = df[num_cols].fillna(0)\n",
        "#     return df\n",
        "\n",
        "# # Convert to numeric\n",
        "# khv_selected = convert_to_numeric(khv_selected, khv_land_col)\n",
        "# rhv_selected = convert_to_numeric(rhv_selected, rhv_land_col)\n",
        "\n",
        "# # Group by land while preserving all departments (summing all numeric columns)\n",
        "# khv_grouped = khv_selected.groupby(khv_land_col, as_index=False).sum()\n",
        "# rhv_grouped = rhv_selected.groupby(rhv_land_col, as_index=False).sum()\n",
        "\n",
        "# # Save to Excel files\n",
        "# khv_grouped.to_excel(\"KHV_2023_Grouped.xlsx\", index=False)\n",
        "# rhv_grouped.to_excel(\"RHV_2023_Grouped.xlsx\", index=False)\n",
        "\n",
        "# # Download the files\n",
        "# files.download(\"KHV_2023_Grouped.xlsx\")\n",
        "# files.download(\"RHV_2023_Grouped.xlsx\")\n",
        "\n",
        "# # Print results\n",
        "# print(\"=\"*50)\n",
        "# print(\"KHV Grouped by Land:\")\n",
        "# print(khv_grouped)\n",
        "\n",
        "# print(\"\\n\" + \"=\"*50)\n",
        "# print(\"RHV Grouped by Land:\")\n",
        "# print(rhv_grouped)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hGQ6OcRGIG1i",
        "outputId": "ab6b8bbc-f604-4ff9-c30f-0cf8cdd32ef0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-12b6c13c-2efc-4f74-93c0-1ff95d1aa932\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-12b6c13c-2efc-4f74-93c0-1ff95d1aa932\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving Krankenhausverzeichnis_2023.xlsx to Krankenhausverzeichnis_2023 (2).xlsx\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-27-cc453ae32cc6>:134: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[col] = pd.to_numeric(df[col], errors='coerce')\n",
            "<ipython-input-27-cc453ae32cc6>:137: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[num_cols] = df[num_cols].fillna(0)\n",
            "<ipython-input-27-cc453ae32cc6>:134: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[col] = pd.to_numeric(df[col], errors='coerce')\n",
            "<ipython-input-27-cc453ae32cc6>:137: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[num_cols] = df[num_cols].fillna(0)\n",
            "<ipython-input-27-cc453ae32cc6>:145: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  khv_grouped = khv_selected.groupby(khv_land_col, as_index=False).sum()\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_0d61d445-6a49-4b52-a989-b191c13d1e04\", \"KHV_2023_Grouped.xlsx\", 15547)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_65c4a3b1-fb0f-43c1-ba1f-2f44ac65e222\", \"RHV_2023_Grouped.xlsx\", 8582)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "KHV Grouped by Land:\n",
            "                Land     INSG     0100   0102    0103   0104   0105  0106  \\\n",
            "0  Baden-Württemberg  53126.0   5880.0  496.0  1921.0  154.0  403.0   0.0   \n",
            "1             Bayern  74565.0  10206.0  515.0   815.0   78.0  224.0  30.0   \n",
            "2             Berlin  20362.0   1648.0    1.0   106.0   95.0   28.0   0.0   \n",
            "3        Brandenburg  14970.0   2611.0   43.0     0.0    0.0   22.0   0.0   \n",
            "4             Bremen   4131.0    656.0    0.0    25.0    0.0    0.0   0.0   \n",
            "\n",
            "     0107   0108  ...   3700  3750  3751   3752   3753  3754   3755  3756  \\\n",
            "0  1439.0  251.0  ...  382.0  28.0   2.0   68.0   13.0   0.0  104.0   0.0   \n",
            "1   590.0  216.0  ...  490.0   3.0   6.0  429.0  356.0   0.0   75.0   0.0   \n",
            "2   147.0   42.0  ...   16.0  85.0   1.0   53.0   22.0   0.0   62.0   0.0   \n",
            "3   100.0    0.0  ...    4.0  26.0   0.0   57.0   26.0   0.0    0.0   0.0   \n",
            "4     0.0    0.0  ...    0.0   0.0   0.0   10.0   19.0   0.0    0.0   0.0   \n",
            "\n",
            "   3757  3758  \n",
            "0   0.0   0.0  \n",
            "1  88.0   0.0  \n",
            "2  22.0   0.0  \n",
            "3   0.0   0.0  \n",
            "4   0.0   0.0  \n",
            "\n",
            "[5 rows x 150 columns]\n",
            "\n",
            "==================================================\n",
            "RHV Grouped by Land:\n",
            "                Land   INSG    0000    0100    0200    0300  0400    0500  \\\n",
            "0  Baden-Württemberg  25818  2060.0  1090.0  1760.0  1827.0   0.0  1042.0   \n",
            "1             Bayern  28651  1656.0   699.0  3104.0  1446.0  55.0  1022.0   \n",
            "2             Berlin    442     0.0     0.0     0.0     0.0   0.0     0.0   \n",
            "3        Brandenburg   5209   155.0   120.0   195.0   463.0   0.0   400.0   \n",
            "4             Bremen    366     0.0     0.0    62.0    44.0   0.0     0.0   \n",
            "\n",
            "    0600   0700  ...  3300  3400  3500  3600    3700   8200    8500   8600  \\\n",
            "0   85.0  179.0  ...   0.0   0.0   0.0   0.0   818.0  430.0  1329.0   92.0   \n",
            "1  191.0  298.0  ...   0.0  62.0   0.0   0.0  1550.0  205.0  1238.0  184.0   \n",
            "2    0.0    0.0  ...   0.0   0.0   0.0   0.0     0.0    0.0     0.0    0.0   \n",
            "3   90.0   40.0  ...   0.0   0.0   0.0   0.0     0.0    0.0   438.0    0.0   \n",
            "4    0.0    0.0  ...   0.0   0.0   0.0   0.0     0.0    0.0    80.0    0.0   \n",
            "\n",
            "    8800  9000  \n",
            "0  181.0   0.0  \n",
            "1  148.0   0.0  \n",
            "2    0.0   0.0  \n",
            "3    0.0   0.0  \n",
            "4    0.0   0.0  \n",
            "\n",
            "[5 rows x 45 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from google.colab import files\n",
        "\n",
        "# Upload the 2023 file\n",
        "uploaded = files.upload()\n",
        "file_name = \"Krankenhausverzeichnis_2023.xlsx\"\n",
        "\n",
        "# Read sheets with correct skipping\n",
        "khv_df = pd.read_excel(file_name, sheet_name=\" KHV_2023\", skiprows=2)\n",
        "rhv_df = pd.read_excel(file_name, sheet_name=\"RHV_2023\", skiprows=2)\n",
        "\n",
        "# Define state mapping dictionary\n",
        "state_mapping = {\n",
        "    '01': 'Schleswig-Holstein',\n",
        "    '02': 'Hamburg',\n",
        "    '03': 'Niedersachsen',\n",
        "    '04': 'Bremen',\n",
        "    '05': 'Nordrhein-Westfalen',\n",
        "    '06': 'Hessen',\n",
        "    '07': 'Rheinland-Pfalz',\n",
        "    '08': 'Baden-Württemberg',\n",
        "    '09': 'Bayern',\n",
        "    '10': 'Saarland',\n",
        "    '11': 'Berlin',\n",
        "    '12': 'Brandenburg',\n",
        "    '13': 'Mecklenburg-Vorpommern',\n",
        "    '14': 'Sachsen',\n",
        "    '15': 'Sachsen-Anhalt',\n",
        "    '16': 'Thüringen'\n",
        "}\n",
        "\n",
        "# Improved function to replace land codes with state names\n",
        "def replace_land_codes(df):\n",
        "    land_col = None\n",
        "    for col in df.columns:\n",
        "        if 'land' in col.lower():\n",
        "            land_col = col\n",
        "            break\n",
        "\n",
        "    if land_col:\n",
        "        # Convert to string and clean\n",
        "        df[land_col] = df[land_col].astype(str).str.strip()\n",
        "\n",
        "        # Handle float values (e.g., '1.0' -> '01', '10.0' -> '10')\n",
        "        df[land_col] = df[land_col].apply(lambda x:\n",
        "            f\"{int(float(x)):02d}\" if '.' in x and x.replace('.', '', 1).isdigit()\n",
        "            else x.zfill(2) if x.isdigit()\n",
        "            else x\n",
        "        )\n",
        "\n",
        "        # Map to state names\n",
        "        df[land_col] = df[land_col].map(state_mapping)\n",
        "        return df, land_col\n",
        "    return df, None\n",
        "\n",
        "# Process both dataframes\n",
        "khv_df, khv_land_col = replace_land_codes(khv_df)\n",
        "rhv_df, rhv_land_col = replace_land_codes(rhv_df)\n",
        "\n",
        "# Define department columns for each sheet\n",
        "# RHV departments\n",
        "rhv_departments = [\n",
        "    'INSG', '0000', '0100', '0200', '0300', '0400', '0500', '0600', '0700', '0800', '0900',\n",
        "    '1000', '1100', '1200', '1300', '1400', '1500', '1600', '1700', '1800', '1900',\n",
        "    '2000', '2100', '2200', '2300', '2400', '2500', '2600', '2700', '2800', '2900',\n",
        "    '3000', '3100', '3200', '3300', '3400', '3500', '3600', '3700',\n",
        "    '8200', '8500', '8600', '8800', '9000'\n",
        "]\n",
        "\n",
        "# KHV departments\n",
        "khv_departments = [\n",
        "    'INSG',\n",
        "    '0100', '0102', '0103', '0104', '0105', '0106', '0107', '0108', '0109', '0114',\n",
        "    '0150', '0151', '0152', '0153', '0154', '0156',\n",
        "    '0200', '0224', '0260', '0261',\n",
        "    '0300',\n",
        "    '0400', '0410', '0436',\n",
        "    '0500', '0510', '0524', '0533',\n",
        "    '0600', '0607', '0610',\n",
        "    '0700', '0706', '0710',\n",
        "    '0800',\n",
        "    '0900', '0910',\n",
        "    '1000', '1004', '1005', '1006', '1007', '1009', '1011', '1012', '1014', '1028', '1050', '1051',\n",
        "    '1100', '1136',\n",
        "    '1200',\n",
        "    '1300',\n",
        "    '1400', '1410',\n",
        "    '1500', '1513', '1516', '1518', '1519', '1520', '1523', '1536', '1550', '1551',\n",
        "    '1600',\n",
        "    '1700',\n",
        "    '1800',\n",
        "    '1900',\n",
        "    '2000', '2021', '2036', '2050',\n",
        "    '2100', '2118', '2120', '2136', '2150',\n",
        "    '2200',\n",
        "    '2300', '2309', '2315', '2316',\n",
        "    '2400', '2402', '2405', '2406', '2425',\n",
        "    '2500',\n",
        "    '2600',\n",
        "    '2700',\n",
        "    '2800', '2810', '2851', '2852', '2856',\n",
        "    '2900', '2928', '2930', '2931', '2950', '2951', '2952', '2953', '2954', '2955', '2956', '2960', '2961',\n",
        "    '3000', '3060', '3061',\n",
        "    '3100', '3110', '3160', '3161',\n",
        "    '3200', '3233',\n",
        "    '3300', '3305', '3350',\n",
        "    '3400', '3460',\n",
        "    '3500',\n",
        "    '3600', '3601', '3603', '3610', '3617', '3618', '3621', '3622', '3624', '3626', '3628', '3650', '3651', '3652',\n",
        "    '3700', '3750', '3751', '3752', '3753', '3754', '3755', '3756', '3757', '3758'\n",
        "]\n",
        "\n",
        "# Convert all column names to strings for matching\n",
        "khv_df.columns = khv_df.columns.astype(str)\n",
        "rhv_df.columns = rhv_df.columns.astype(str)\n",
        "\n",
        "# Select only land column and department columns that exist in the dataframe\n",
        "def select_departments(df, land_col, departments):\n",
        "    # Find columns that actually exist in the dataframe\n",
        "    existing_cols = [col for col in departments if col in df.columns]\n",
        "    return df[[land_col] + existing_cols]\n",
        "\n",
        "# Select relevant columns\n",
        "khv_selected = select_departments(khv_df, khv_land_col, khv_departments)\n",
        "rhv_selected = select_departments(rhv_df, rhv_land_col, rhv_departments)\n",
        "\n",
        "# Convert all department columns to numeric\n",
        "def convert_to_numeric(df, land_col):\n",
        "    # Identify numeric columns (all except land column)\n",
        "    num_cols = [col for col in df.columns if col != land_col]\n",
        "\n",
        "    # Convert to numeric, coercing errors to NaN\n",
        "    for col in num_cols:\n",
        "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "    # Fill NaN with 0\n",
        "    df[num_cols] = df[num_cols].fillna(0)\n",
        "    return df\n",
        "\n",
        "# Convert to numeric\n",
        "khv_selected = convert_to_numeric(khv_selected, khv_land_col)\n",
        "rhv_selected = convert_to_numeric(rhv_selected, rhv_land_col)\n",
        "\n",
        "# Group by land while preserving all departments (summing all numeric columns)\n",
        "khv_grouped = khv_selected.groupby(khv_land_col, as_index=False).sum()\n",
        "rhv_grouped = rhv_selected.groupby(rhv_land_col, as_index=False).sum()\n",
        "\n",
        "# Save to Excel files\n",
        "khv_grouped.to_excel(\"KHV_2023_Grouped.xlsx\", index=False)\n",
        "rhv_grouped.to_excel(\"RHV_2023_Grouped.xlsx\", index=False)\n",
        "\n",
        "# Download the files\n",
        "files.download(\"KHV_2023_Grouped.xlsx\")\n",
        "files.download(\"RHV_2023_Grouped.xlsx\")\n",
        "\n",
        "# Print results\n",
        "print(\"=\"*50)\n",
        "print(\"KHV Grouped by Land:\")\n",
        "print(khv_grouped.head())\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"RHV Grouped by Land:\")\n",
        "print(rhv_grouped.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "id": "DIvpTdrV40Pm",
        "outputId": "217f4349-1589-43dd-9c03-95bc20b12a9d"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_a48a1212-856f-4694-a35a-bb8d13ba2a2b\", \"Krankenhausverzeichnis_2021_Grouped.xlsx\", 7312)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "Successfully created Excel file with 2 sheets: Krankenhausverzeichnis_2021_Grouped.xlsx\n",
            "==================================================\n",
            "- Sheet 'KHV_2021_Grouped': 0 states x 150 columns\n",
            "- Sheet 'RHV_2021_Grouped': 0 states x 45 columns\n"
          ]
        }
      ],
      "source": [
        "output_file = \"Krankenhausverzeichnis_2021_Grouped.xlsx\"\n",
        "\n",
        "with pd.ExcelWriter(output_file) as writer:\n",
        "    khv_grouped.to_excel(writer, sheet_name=\"KHV_2021_Grouped\", index=False)\n",
        "    rhv_grouped.to_excel(writer, sheet_name=\"RHV_2021_Grouped\", index=False)\n",
        "\n",
        "# Download the file\n",
        "files.download(output_file)\n",
        "\n",
        "# Print confirmation\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(f\"Successfully created Excel file with 2 sheets: {output_file}\")\n",
        "print(\"=\"*50)\n",
        "print(f\"- Sheet 'KHV_2021_Grouped': {khv_grouped.shape[0]} states x {khv_grouped.shape[1]} columns\")\n",
        "print(f\"- Sheet 'RHV_2021_Grouped': {rhv_grouped.shape[0]} states x {rhv_grouped.shape[1]} columns\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1mv8WVAAQaZ",
        "outputId": "9244fe92-ed89-4d1e-c676-bce0b9e064ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting xlsxwriter\n",
            "  Downloading XlsxWriter-3.2.3-py3-none-any.whl.metadata (2.7 kB)\n",
            "Downloading XlsxWriter-3.2.3-py3-none-any.whl (169 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/169.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/169.4 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.4/169.4 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xlsxwriter\n",
            "Successfully installed xlsxwriter-3.2.3\n"
          ]
        }
      ],
      "source": [
        "!pip install xlsxwriter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "id": "JdRiSmCN40Rx",
        "outputId": "5aa329de-0e4e-483c-b137-6dea08d43217"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File /Krankenhausverzeichnis_2021.xlsx not found in uploaded files. Skipping.\n",
            "File /Krankenhausverzeichnis_2022.xlsx not found in uploaded files. Skipping.\n",
            "File /Krankenhausverzeichnis_2023.xlsx not found in uploaded files. Skipping.\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_77d8267c-a80e-427f-a491-c0ff1aa1cd66\", \"Krankenhausverzeichnis_All_Years_Grouped.xlsx\", 4917)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "All years processed successfully!\n",
            "Combined Excel file downloaded: /Krankenhausverzeichnis_All_Years_Grouped.xlsx\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "# Define state mapping dictionary\n",
        "state_mapping = {\n",
        "    '01': 'Schleswig-Holstein',\n",
        "    '02': 'Hamburg',\n",
        "    '03': 'Niedersachsen',\n",
        "    '04': 'Bremen',\n",
        "    '05': 'Nordrhein-Westfalen',\n",
        "    '06': 'Hessen',\n",
        "    '07': 'Rheinland-Pfalz',\n",
        "    '08': 'Baden-Württemberg',\n",
        "    '09': 'Bayern',\n",
        "    '10': 'Saarland',\n",
        "    '11': 'Berlin',\n",
        "    '12': 'Brandenburg',\n",
        "    '13': 'Mecklenburg-Vorpommern',\n",
        "    '14': 'Sachsen',\n",
        "    '15': 'Sachsen-Anhalt',\n",
        "    '16': 'Thüringen'\n",
        "}\n",
        "\n",
        "# Define department columns for each sheet type\n",
        "# RHV departments\n",
        "rhv_departments = [\n",
        "    'INSG', '0000', '0100', '0200', '0300', '0400', '0500', '0600', '0700', '0800', '0900',\n",
        "    '1000', '1100', '1200', '1300', '1400', '1500', '1600', '1700', '1800', '1900',\n",
        "    '2000', '2100', '2200', '2300', '2400', '2500', '2600', '2700', '2800', '2900',\n",
        "    '3000', '3100', '3200', '3300', '3400', '3500', '3600', '3700',\n",
        "    '8200', '8500', '8600', '8800', '9000'\n",
        "]\n",
        "\n",
        "# KHV departments\n",
        "khv_departments = [\n",
        "    'INSG',\n",
        "    '0100', '0102', '0103', '0104', '0105', '0106', '0107', '0108', '0109', '0114',\n",
        "    '0150', '0151', '0152', '0153', '0154', '0156',\n",
        "    '0200', '0224', '0260', '0261',\n",
        "    '0300',\n",
        "    '0400', '0410', '0436',\n",
        "    '0500', '0510', '0524', '0533',\n",
        "    '0600', '0607', '0610',\n",
        "    '0700', '0706', '0710',\n",
        "    '0800',\n",
        "    '0900', '0910',\n",
        "    '1000', '1004', '1005', '1006', '1007', '1009', '1011', '1012', '1014', '1028', '1050', '1051',\n",
        "    '1100', '1136',\n",
        "    '1200',\n",
        "    '1300',\n",
        "    '1400', '1410',\n",
        "    '1500', '1513', '1516', '1518', '1519', '1520', '1523', '1536', '1550', '1551',\n",
        "    '1600',\n",
        "    '1700',\n",
        "    '1800',\n",
        "    '1900',\n",
        "    '2000', '2021', '2036', '2050',\n",
        "    '2100', '2118', '2120', '2136', '2150',\n",
        "    '2200',\n",
        "    '2300', '2309', '2315', '2316',\n",
        "    '2400', '2402', '2405', '2406', '2425',\n",
        "    '2500',\n",
        "    '2600',\n",
        "    '2700',\n",
        "    '2800', '2810', '2851', '2852', '2856',\n",
        "    '2900', '2928', '2930', '2931', '2950', '2951', '2952', '2953', '2954', '2955', '2956', '2960', '2961',\n",
        "    '3000', '3060', '3061',\n",
        "    '3100', '3110', '3160', '3161',\n",
        "    '3200', '3233',\n",
        "    '3300', '3305', '3350',\n",
        "    '3400', '3460',\n",
        "    '3500',\n",
        "    '3600', '3601', '3603', '3610', '3617', '3618', '3621', '3622', '3624', '3626', '3628', '3650', '3651', '3652',\n",
        "    '3700', '3750', '3751', '3752', '3753', '3754', '3755', '3756', '3757', '3758'\n",
        "]\n",
        "\n",
        "# Function to replace land codes with state names\n",
        "def replace_land_codes(df):\n",
        "    land_col = None\n",
        "    for col in df.columns:\n",
        "        if 'land' in col.lower():\n",
        "            land_col = col\n",
        "            break\n",
        "\n",
        "    if land_col:\n",
        "        df[land_col] = df[land_col].astype(str).str.strip().str.zfill(2)\n",
        "        df[land_col] = df[land_col].map(state_mapping)\n",
        "        return df, land_col\n",
        "    return df, None\n",
        "\n",
        "# Function to select departments\n",
        "def select_departments(df, land_col, departments):\n",
        "    # Convert all column names to strings for matching\n",
        "    df.columns = df.columns.astype(str)\n",
        "    # Find columns that actually exist in the dataframe\n",
        "    existing_cols = [col for col in departments if col in df.columns]\n",
        "    return df[[land_col] + existing_cols]\n",
        "\n",
        "# Function to convert to numeric\n",
        "def convert_to_numeric(df, land_col):\n",
        "    # Identify numeric columns\n",
        "    num_cols = [col for col in df.columns if col != land_col]\n",
        "    # Convert to numeric\n",
        "    for col in num_cols:\n",
        "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "    # Fill NaN with 0\n",
        "    df[num_cols] = df[num_cols].fillna(0)\n",
        "    return df\n",
        "\n",
        "# # Upload files\n",
        "# print(\"Please upload all three Excel files:\")\n",
        "# uploaded = files.upload()\n",
        "\n",
        "# Create Excel writer for combined output\n",
        "combined_output = \"/Krankenhausverzeichnis_All_Years_Grouped.xlsx\"\n",
        "writer = pd.ExcelWriter(combined_output, engine='xlsxwriter')\n",
        "\n",
        "# Process each year\n",
        "years = [2021, 2022, 2023]\n",
        "for year in years:\n",
        "    file_name = f\"/Krankenhausverzeichnis_{year}.xlsx\"\n",
        "\n",
        "    # Check if file exists\n",
        "    if file_name not in uploaded:\n",
        "        print(f\"File {file_name} not found in uploaded files. Skipping.\")\n",
        "        continue\n",
        "\n",
        "    # Read sheets\n",
        "    try:\n",
        "        khv_df = pd.read_excel(file_name, sheet_name=f\"KHV_{year}\", skiprows=4)\n",
        "        rhv_df = pd.read_excel(file_name, sheet_name=f\"RHV_{year}\", skiprows=4)\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading {file_name}: {e}\")\n",
        "        continue\n",
        "\n",
        "    # Process KHV data\n",
        "    khv_df, khv_land_col = replace_land_codes(khv_df)\n",
        "    khv_selected = select_departments(khv_df, khv_land_col, khv_departments)\n",
        "    khv_selected = convert_to_numeric(khv_selected, khv_land_col)\n",
        "    khv_grouped = khv_selected.groupby(khv_land_col, as_index=False).sum()\n",
        "\n",
        "    # Process RHV data\n",
        "    rhv_df, rhv_land_col = replace_land_codes(rhv_df)\n",
        "    rhv_selected = select_departments(rhv_df, rhv_land_col, rhv_departments)\n",
        "    rhv_selected = convert_to_numeric(rhv_selected, rhv_land_col)\n",
        "    rhv_grouped = rhv_selected.groupby(rhv_land_col, as_index=False).sum()\n",
        "\n",
        "    # Save to combined Excel\n",
        "    khv_grouped.to_excel(writer, sheet_name=f\"KHV_{year}\", index=False)\n",
        "    rhv_grouped.to_excel(writer, sheet_name=f\"RHV_{year}\", index=False)\n",
        "\n",
        "    print(f\"Processed {year} data successfully\")\n",
        "\n",
        "# Save and close the Excel writer\n",
        "writer.close()\n",
        "\n",
        "# Download the combined file\n",
        "files.download(combined_output)\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"All years processed successfully!\")\n",
        "print(f\"Combined Excel file downloaded: {combined_output}\")\n",
        "print(\"=\"*50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7zdd1E_540UI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xv-wl0bX40WX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B-7U31kj40YY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GiMBmnuK40ak"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zIlyjsMa40c_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x2sHBPhI40fH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XManyxSUbs5-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "er5Hai33RQ2b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yjuVciLLRQ41"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Rf__wtGMjl9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GI9UsB_JMjn7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "yGhUvM8RKDq4",
        "outputId": "7aafaf58-a796-4a28-d11f-da9bca9a6399"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total states processed: 16\n",
            "Department columns included: 151\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "state_capacity"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-c18f0f81-ec59-4403-80ff-a70a27f267ae\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>State_Code</th>\n",
              "      <th>State_Name</th>\n",
              "      <th>INSG</th>\n",
              "      <th>0100</th>\n",
              "      <th>0102</th>\n",
              "      <th>0103</th>\n",
              "      <th>0104</th>\n",
              "      <th>0105</th>\n",
              "      <th>0106</th>\n",
              "      <th>0107</th>\n",
              "      <th>...</th>\n",
              "      <th>3750</th>\n",
              "      <th>3751</th>\n",
              "      <th>3752</th>\n",
              "      <th>3753</th>\n",
              "      <th>3754</th>\n",
              "      <th>3755</th>\n",
              "      <th>3756</th>\n",
              "      <th>3757</th>\n",
              "      <th>3758</th>\n",
              "      <th>3759</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>Schleswig-Holstein</td>\n",
              "      <td>15562.0</td>\n",
              "      <td>2664.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>244.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>97.0</td>\n",
              "      <td>154.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.0</td>\n",
              "      <td>Hamburg</td>\n",
              "      <td>12996.0</td>\n",
              "      <td>823.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>14.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.0</td>\n",
              "      <td>Niedersachsen</td>\n",
              "      <td>40676.0</td>\n",
              "      <td>9219.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>209.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>101.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.0</td>\n",
              "      <td>Bremen</td>\n",
              "      <td>4131.0</td>\n",
              "      <td>656.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>Nordrhein-Westfalen</td>\n",
              "      <td>112610.0</td>\n",
              "      <td>21332.0</td>\n",
              "      <td>184.0</td>\n",
              "      <td>1389.0</td>\n",
              "      <td>252.0</td>\n",
              "      <td>544.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>616.0</td>\n",
              "      <td>...</td>\n",
              "      <td>35.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>268.0</td>\n",
              "      <td>205.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>119.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 153 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c18f0f81-ec59-4403-80ff-a70a27f267ae')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c18f0f81-ec59-4403-80ff-a70a27f267ae button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c18f0f81-ec59-4403-80ff-a70a27f267ae');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-4bb24f53-5c44-4cf7-93d8-f5720a69e934\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4bb24f53-5c44-4cf7-93d8-f5720a69e934')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-4bb24f53-5c44-4cf7-93d8-f5720a69e934 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   State_Code           State_Name      INSG     0100   0102    0103   0104  \\\n",
              "0         1.0   Schleswig-Holstein   15562.0   2664.0    0.0   244.0    0.0   \n",
              "1         2.0              Hamburg   12996.0    823.0    0.0    35.0    0.0   \n",
              "2         3.0        Niedersachsen   40676.0   9219.0   64.0   209.0    0.0   \n",
              "3         4.0               Bremen    4131.0    656.0    0.0    25.0    0.0   \n",
              "4         5.0  Nordrhein-Westfalen  112610.0  21332.0  184.0  1389.0  252.0   \n",
              "\n",
              "    0105  0106   0107  ...  3750  3751   3752   3753  3754  3755  3756   3757  \\\n",
              "0   51.0   0.0   62.0  ...   0.0   0.0   97.0  154.0   0.0   1.0   0.0   29.0   \n",
              "1   42.0   0.0    0.0  ...  14.0   0.0   25.0    0.0   0.0   8.0   0.0   33.0   \n",
              "2   33.0   0.0  101.0  ...   0.0   0.0   45.0    0.0   0.0   0.0   0.0    0.0   \n",
              "3    0.0   0.0    0.0  ...   0.0   0.0   10.0   19.0   0.0   0.0   0.0    0.0   \n",
              "4  544.0  27.0  616.0  ...  35.0   5.0  268.0  205.0  32.0  60.0   0.0  119.0   \n",
              "\n",
              "   3758  3759  \n",
              "0   0.0   0.0  \n",
              "1   0.0   0.0  \n",
              "2   0.0   0.0  \n",
              "3   0.0   0.0  \n",
              "4   0.0   0.0  \n",
              "\n",
              "[5 rows x 153 columns]"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Read the Excel file\n",
        "file_path = \"/Krankenhausverzeichnis_2023.xlsx\"\n",
        "\n",
        "# Load the hospital directory sheet (KHV_2023)\n",
        "# Skip first 2 rows of the sheet as they contain titles/empty rows\n",
        "df = pd.read_excel(file_path, sheet_name=\" KHV_2023\", header=2)\n",
        "\n",
        "# Filter out empty rows (where state code is missing)\n",
        "df = df[df['Land'].notna()]\n",
        "\n",
        "# Identify department columns (all columns after 'INSG')\n",
        "cols = df.columns.tolist()\n",
        "insg_index = cols.index('INSG')\n",
        "department_columns = cols[insg_index:]\n",
        "\n",
        "# Convert department columns to numeric (handle empty values)\n",
        "for col in department_columns:\n",
        "    df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)\n",
        "\n",
        "# Group by state and sum capacities\n",
        "state_capacity = df.groupby('Land')[department_columns].sum()\n",
        "\n",
        "# Reset index for better formatting\n",
        "state_capacity = state_capacity.reset_index()\n",
        "\n",
        "# Rename columns for readability\n",
        "state_capacity.rename(columns={'Land': 'State_Code'}, inplace=True)\n",
        "\n",
        "# Add state names mapping (based on German state codes)\n",
        "state_names = {\n",
        "    '01': 'Schleswig-Holstein',\n",
        "    '02': 'Hamburg',\n",
        "    '03': 'Niedersachsen',\n",
        "    '04': 'Bremen',\n",
        "    '05': 'Nordrhein-Westfalen',\n",
        "    '06': 'Hessen',\n",
        "    '07': 'Rheinland-Pfalz',\n",
        "    '08': 'Baden-Württemberg',\n",
        "    '09': 'Bayern',\n",
        "    '10': 'Saarland',\n",
        "    '11': 'Berlin',\n",
        "    '12': 'Brandenburg',\n",
        "    '13': 'Mecklenburg-Vorpommern',\n",
        "    '14': 'Sachsen',\n",
        "    '15': 'Sachsen-Anhalt',\n",
        "    '16': 'Thüringen'\n",
        "}\n",
        "\n",
        "state_capacity['State_Name'] = state_capacity['State_Code'].apply(\n",
        "    lambda x: state_names.get(str(int(x)).zfill(2), 'Unknown')\n",
        ")\n",
        "\n",
        "# Reorder columns\n",
        "state_capacity = state_capacity[['State_Code', 'State_Name'] + department_columns]\n",
        "\n",
        "# Display results\n",
        "print(f\"Total states processed: {len(state_capacity)}\")\n",
        "print(f\"Department columns included: {len(department_columns)}\")\n",
        "state_capacity.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "FkxApjihKDtd",
        "outputId": "ce0934c1-4361-4488-96ce-48af7fa4df9a"
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Configuration\n",
        "YEARS = [2021, 2022, 2023]\n",
        "STATE_CODES = {\n",
        "    '01': 'Schleswig-Holstein',\n",
        "    '02': 'Hamburg',\n",
        "    '03': 'Niedersachsen',\n",
        "    '04': 'Bremen',\n",
        "    '05': 'Nordrhein-Westfalen',\n",
        "    '06': 'Hessen',\n",
        "    '07': 'Rheinland-Pfalz',\n",
        "    '08': 'Baden-Württemberg',\n",
        "    '09': 'Bayern',\n",
        "    '10': 'Saarland',\n",
        "    '11': 'Berlin',\n",
        "    '12': 'Brandenburg',\n",
        "    '13': 'Mecklenburg-Vorpommern',\n",
        "    '14': 'Sachsen',\n",
        "    '15': 'Sachsen-Anhalt',\n",
        "    '16': 'Thüringen'\n",
        "}\n",
        "\n",
        "# Initialize storage\n",
        "all_data = []\n",
        "\n",
        "# Process each year's file\n",
        "for year in YEARS:\n",
        "    file_path = f\"Krankenhausverzeichnis_{year}.xlsx\"\n",
        "    sheet_name = f\"KHV_{year}\"\n",
        "\n",
        "    # Read data (skip first 2 header rows)\n",
        "    df = pd.read_excel(file_path, sheet_name=sheet_name, header=2)\n",
        "\n",
        "    # Filter valid entries and convert state codes\n",
        "    df = df[df['Land'].notna()]\n",
        "    df['Land'] = df['Land'].astype(int).astype(str).str.zfill(2)\n",
        "\n",
        "    # Convert department beds to numeric\n",
        "    insg_index = df.columns.get_loc('INSG')\n",
        "    dept_cols = df.columns[insg_index:]\n",
        "    df[dept_cols] = df[dept_cols].apply(pd.to_numeric, errors='coerce').fillna(0)\n",
        "\n",
        "    # Aggregate state-level totals\n",
        "    state_totals = df.groupby('Land')[['INSG'] + list(dept_cols)].sum()\n",
        "    state_totals = state_totals.reset_index()\n",
        "    state_totals['Year'] = year\n",
        "\n",
        "    # Add to combined dataset\n",
        "    all_data.append(state_totals)\n",
        "\n",
        "# Combine all years\n",
        "combined = pd.concat(all_data).reset_index(drop=True)\n",
        "\n",
        "# Add state names\n",
        "combined['State_Name'] = combined['Land'].map(STATE_CODES)\n",
        "\n",
        "# Calculate year-over-year growth\n",
        "combined = combined.sort_values(['Land', 'Year'])\n",
        "growth_df = combined.set_index(['Land', 'State_Name', 'Year'])\n",
        "\n",
        "# Calculate growth rates for each metric\n",
        "for col in growth_df.columns:\n",
        "    if col != 'Land':\n",
        "        growth_df[f'{col}_Growth'] = growth_df.groupby('Land')[col].pct_change() * 100\n",
        "\n",
        "growth_df = growth_df.reset_index()\n",
        "\n",
        "# Filter to most recent years for analysis\n",
        "trend_df = growth_df[growth_df['Year'] >= 2022]\n",
        "\n",
        "# Visualization 1: Overall capacity trend\n",
        "plt.figure(figsize=(14, 7))\n",
        "sns.lineplot(data=combined, x='Year', y='INSG', hue='State_Name',\n",
        "             marker='o', linewidth=2.5)\n",
        "plt.title('Total Hospital Bed Capacity by State (2021-2023)')\n",
        "plt.ylabel('Total Beds')\n",
        "plt.grid(alpha=0.3)\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Visualization 2: Growth rate comparison\n",
        "plt.figure(figsize=(14, 7))\n",
        "sns.barplot(data=trend_df, x='State_Name', y='INSG_Growth', hue='Year')\n",
        "plt.title('Year-over-Year Bed Capacity Growth (%)')\n",
        "plt.axhline(0, color='black', linestyle='--')\n",
        "plt.ylabel('Growth Rate %')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Visualization 3: Department growth\n",
        "dept_growth = trend_df.melt(\n",
        "    id_vars=['State_Name', 'Year'],\n",
        "    value_vars=[col for col in trend_df if '_Growth' in col and 'INSG' not in col],\n",
        "    var_name='Department',\n",
        "    value_name='Growth'\n",
        ")\n",
        "\n",
        "# Clean department names\n",
        "dept_growth['Department'] = dept_growth['Department'].str.replace('_Growth', '')\n",
        "plt.figure(figsize=(16, 8))\n",
        "sns.boxplot(data=dept_growth, x='Department', y='Growth')\n",
        "plt.title('Departmental Growth Rate Distribution (2022-2023)')\n",
        "plt.ylabel('Growth Rate %')\n",
        "plt.xticks(rotation=90)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Generate summary statistics\n",
        "summary = growth_df.groupby('State_Name').agg(\n",
        "    Total_Beds_2021=('INSG', lambda x: x.iloc[0]),\n",
        "    Total_Beds_2023=('INSG', lambda x: x.iloc[-1]),\n",
        "    Overall_Growth=('INSG_Growth', 'sum')\n",
        ").reset_index()\n",
        "\n",
        "# Add most improved department\n",
        "def get_top_growth_dept(group):\n",
        "    dept_cols = [col for col in group if '_Growth' in col and col != 'INSG_Growth']\n",
        "    max_growth = group[dept_cols].mean().idxmax()\n",
        "    return max_growth.replace('_Growth', '')\n",
        "\n",
        "top_depts = growth_df.groupby('State_Name').apply(get_top_growth_dept).reset_index()\n",
        "top_depts.columns = ['State_Name', 'Fastest_Growing_Dept']\n",
        "summary = summary.merge(top_depts, on='State_Name')\n",
        "\n",
        "# Show summary table\n",
        "print(\"\\nState Capacity Growth Summary:\")\n",
        "summary.sort_values('Overall_Growth', ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "KHV_2000_Grouped\n"
          ]
        }
      ],
      "source": [
        "year = 2000\n",
        "print(f'KHV_{year}_Grouped')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "GlPblL9BKDvq"
      },
      "outputs": [],
      "source": [
        "# combine patien\n",
        "years_files = {\n",
        "    2021: \"../Data/State_MDC_Aggregation_2021.xlsx\",\n",
        "    2022: \"../Data/State_MDC_Aggregation_2022.xlsx\",\n",
        "    2023: \"../Data/State_MDC_Aggregation_2023.xlsx\"\n",
        "}\n",
        "import pandas as pd\n",
        "for year, path in years_files.items():\n",
        "    df1 = pd.read_excel(path, sheet_name='State_MDC_Aggregation')\n",
        "    df2 = pd.read_excel(\"../Data/Krankenhausverzeichnis_All_Years_Grouper.xlsx\", sheet_name=f'KHV_{year}_Grouped')\n",
        "    df3 = pd.read_excel(\"../Data/Krankenhausverzeichnis_All_Years_Grouper.xlsx\", sheet_name=f'RHV_{year}_Grouped')\n",
        "    merged_df = pd.merge(df1,df2, left_on='state', right_on='Land', how='left')\n",
        "    merged_df = pd.merge(merged_df,df3, left_on='state', right_on='Land', how='left')\n",
        "    merged_df.to_excel(f'../Data/merged_{year}.xlsx', index=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cv1_wB5mKAQx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "beoX_O3lKATM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KRN1QoIJKAVg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uF-ftZbuKAX2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KC2WjEGnKAZ2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4O42BYIoKBJe"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UF9IaFa-KBLq"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "conv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
